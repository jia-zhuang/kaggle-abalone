{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e3d197-422d-43d2-ad93-de0936b756b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "023d634f-45a8-41ae-89fb-688970c414eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866ea0e-bf79-4489-a89d-4d8abd5c3f8d",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f01fa8-4957-4ec1-8370-b5fb5c514f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5e69e5-17c3-4bb3-be87-685ca64749ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f76f7100-fe21-4f02-ad6c-cc854309a245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90615, 60411)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0], test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c2d68-4190-4c4a-8142-89998e3d6976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e905a937-f4ec-4482-bdc9-713fd10f5f08",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322e9703-4a38-4988-bc44-2613fe03b38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "      <td>90615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45307.000000</td>\n",
       "      <td>0.517098</td>\n",
       "      <td>0.401679</td>\n",
       "      <td>0.135464</td>\n",
       "      <td>0.789035</td>\n",
       "      <td>0.340778</td>\n",
       "      <td>0.169422</td>\n",
       "      <td>0.225898</td>\n",
       "      <td>9.696794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26158.441658</td>\n",
       "      <td>0.118217</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.038008</td>\n",
       "      <td>0.457671</td>\n",
       "      <td>0.204428</td>\n",
       "      <td>0.100909</td>\n",
       "      <td>0.130203</td>\n",
       "      <td>3.176221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22653.500000</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45307.000000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67960.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.067500</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90614.000000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        Length      Diameter        Height  Whole weight  \\\n",
       "count  90615.000000  90615.000000  90615.000000  90615.000000  90615.000000   \n",
       "mean   45307.000000      0.517098      0.401679      0.135464      0.789035   \n",
       "std    26158.441658      0.118217      0.098026      0.038008      0.457671   \n",
       "min        0.000000      0.075000      0.055000      0.000000      0.002000   \n",
       "25%    22653.500000      0.445000      0.345000      0.110000      0.419000   \n",
       "50%    45307.000000      0.545000      0.425000      0.140000      0.799500   \n",
       "75%    67960.500000      0.600000      0.470000      0.160000      1.067500   \n",
       "max    90614.000000      0.815000      0.650000      1.130000      2.825500   \n",
       "\n",
       "       Whole weight.1  Whole weight.2  Shell weight         Rings  \n",
       "count    90615.000000    90615.000000  90615.000000  90615.000000  \n",
       "mean         0.340778        0.169422      0.225898      9.696794  \n",
       "std          0.204428        0.100909      0.130203      3.176221  \n",
       "min          0.001000        0.000500      0.001500      1.000000  \n",
       "25%          0.177500        0.086500      0.120000      8.000000  \n",
       "50%          0.330000        0.166000      0.225000      9.000000  \n",
       "75%          0.463000        0.232500      0.305000     11.000000  \n",
       "max          1.488000        0.760000      1.005000     29.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72a63a0-2f8e-401c-aea9-e9765cced5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "I    33093\n",
       "M    31027\n",
       "F    26495\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecb4bab-6942-4da9-b7ef-d187ab7bfe66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rings\n",
       "9     17465\n",
       "8     14499\n",
       "10    12464\n",
       "7      9008\n",
       "11     8407\n",
       "6      5411\n",
       "12     4719\n",
       "13     4074\n",
       "5      2862\n",
       "14     2507\n",
       "15     2072\n",
       "16     1439\n",
       "4      1402\n",
       "17     1175\n",
       "18      848\n",
       "19      639\n",
       "20      507\n",
       "3       386\n",
       "21      255\n",
       "23      180\n",
       "22      108\n",
       "27       41\n",
       "2        29\n",
       "24       29\n",
       "1        25\n",
       "29       24\n",
       "25       22\n",
       "26       18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Rings.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586b145-220a-4d04-8959-48a61e65623d",
   "metadata": {},
   "source": [
    "## 建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43977216-c9b6-4e62-8ea0-30dbf24d8be8",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71d56d7a-b2cc-47ad-879a-a96c34c9851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex2code = {'I': 0, 'M': 1, 'F': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54a0cc37-0de6-4dd5-8bd4-a34eee70cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Sex_code'] = train_df.Sex.map(Sex2code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4931233c-4b50-4469-94df-b6b11bdd60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Sex_code'] = test_df.Sex.map(Sex2code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecaf7286-8062-4091-afe5-d5e60601b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [c for c in train_df.columns if c not in {'Rings', 'Sex'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aad1a421-4e9f-4fdf-b6fa-f3fa72919264",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Rings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25454d1c-c6cb-452b-a464-6a1c388124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_threads': 8,\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'lambda_l1': 1,\n",
    "    'metric': 'l2',\n",
    "    'early_stopping_rounds': 400,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1c7942a-e51a-46e9-80eb-db7e03ade08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce5de0f5-e52f-453a-8700-4fd08ca665e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 72492, number of used features: 9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.697111\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.51479\n",
      "[200]\tvalid_0's l2: 3.48367\n",
      "[300]\tvalid_0's l2: 3.46954\n",
      "[400]\tvalid_0's l2: 3.46569\n",
      "[500]\tvalid_0's l2: 3.4662\n",
      "[600]\tvalid_0's l2: 3.47167\n",
      "[700]\tvalid_0's l2: 3.47084\n",
      "[800]\tvalid_0's l2: 3.47714\n",
      "Early stopping, best iteration is:\n",
      "[427]\tvalid_0's l2: 3.46325\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 72492, number of used features: 9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.704657\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.38939\n",
      "[200]\tvalid_0's l2: 3.35816\n",
      "[300]\tvalid_0's l2: 3.34359\n",
      "[400]\tvalid_0's l2: 3.33829\n",
      "[500]\tvalid_0's l2: 3.34186\n",
      "[600]\tvalid_0's l2: 3.35071\n",
      "[700]\tvalid_0's l2: 3.35649\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's l2: 3.33716\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 72492, number of used features: 9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.692987\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.43839\n",
      "[200]\tvalid_0's l2: 3.40248\n",
      "[300]\tvalid_0's l2: 3.39601\n",
      "[400]\tvalid_0's l2: 3.39079\n",
      "[500]\tvalid_0's l2: 3.39356\n",
      "[600]\tvalid_0's l2: 3.39675\n",
      "[700]\tvalid_0's l2: 3.40362\n",
      "[800]\tvalid_0's l2: 3.41456\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's l2: 3.38833\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 72492, number of used features: 9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.694270\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.41845\n",
      "[200]\tvalid_0's l2: 3.40323\n",
      "[300]\tvalid_0's l2: 3.40034\n",
      "[400]\tvalid_0's l2: 3.40203\n",
      "[500]\tvalid_0's l2: 3.40726\n",
      "[600]\tvalid_0's l2: 3.41836\n",
      "[700]\tvalid_0's l2: 3.42234\n",
      "Early stopping, best iteration is:\n",
      "[345]\tvalid_0's l2: 3.39736\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1583\n",
      "[LightGBM] [Info] Number of data points in the train set: 72492, number of used features: 9\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.694946\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.31576\n",
      "[200]\tvalid_0's l2: 3.28611\n",
      "[300]\tvalid_0's l2: 3.29252\n",
      "[400]\tvalid_0's l2: 3.29339\n",
      "[500]\tvalid_0's l2: 3.29178\n",
      "[600]\tvalid_0's l2: 3.30053\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's l2: 3.28379\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(train_df.shape[0])\n",
    "pred = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index)):\n",
    "    print(f'fold={i}', '- ' * 20)\n",
    "    trn_data = lgb.Dataset(train_df.loc[trn_idx, train_cols], label=train_df.loc[trn_idx, target_col], categorical_feature=['Sex_code'])\n",
    "    val_data = lgb.Dataset(train_df.loc[val_idx, train_cols], label=train_df.loc[val_idx, target_col], categorical_feature=['Sex_code'])\n",
    "\n",
    "    model = lgb.train(params, trn_data, 10000, valid_sets=val_data, callbacks=[lgb.log_evaluation(100)])\n",
    "\n",
    "    oof[val_idx] = model.predict(train_df.loc[val_idx, train_cols], num_iteration=model.best_iteration)\n",
    "    pred += model.predict(test_df[train_cols], num_iteration=model.best_iteration)\n",
    "\n",
    "    importance_df = pd.DataFrame()\n",
    "    importance_df['feature'] = train_cols\n",
    "    importance_df['importance'] = model.feature_importance()\n",
    "    importance_df['fold'] = i\n",
    "    feature_importance_df.append(importance_df)\n",
    "\n",
    "feature_importance_df = pd.concat(feature_importance_df, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd8b8d4e-5514-434c-b3c1-082271be23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['oof'] = oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bd5f761-961a-4ae3-9805-84dd2f916796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_code</th>\n",
       "      <th>oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10.016144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10.863612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.054129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10.487924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8.481230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
       "0   0   F   0.550     0.430   0.150        0.7715          0.3285   \n",
       "1   1   F   0.630     0.490   0.145        1.1300          0.4580   \n",
       "2   2   I   0.160     0.110   0.025        0.0210          0.0055   \n",
       "3   3   M   0.595     0.475   0.150        0.9145          0.3755   \n",
       "4   4   I   0.555     0.425   0.130        0.7820          0.3695   \n",
       "\n",
       "   Whole weight.2  Shell weight  Rings  Sex_code        oof  \n",
       "0          0.1465        0.2400     11         2  10.016144  \n",
       "1          0.2765        0.3200     11         2  10.863612  \n",
       "2          0.0030        0.0050      6         0   4.054129  \n",
       "3          0.2055        0.2500     10         1  10.487924  \n",
       "4          0.1600        0.1975      9         0   8.481230  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be366e6c-23d9-4661-917c-2244d8032e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fae40349f40>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_df.Rings, train_df.oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187ff2-57fc-4e6a-ac7b-3a46ec0f818b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ecd8c-332a-4bbd-b054-760f2b927a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7b1e7-97d4-44be-b56c-b830a6e22bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21112c64-e4c5-4032-8ea7-9f1950b5ab7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b22e07a-533d-4f8a-8acd-22eb4f0e3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(train_df[train_cols], label=train_df['Rings'], categorical_feature=['Sex_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13fc6616-9d4d-4a67-bb1a-96cb4beb031a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1590\n",
      "[LightGBM] [Info] Number of data points in the train set: 67959, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1590\n",
      "[LightGBM] [Info] Number of data points in the train set: 67959, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1590\n",
      "[LightGBM] [Info] Number of data points in the train set: 67959, number of used features: 9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1590\n",
      "[LightGBM] [Info] Number of data points in the train set: 67959, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 9.689504\n",
      "[LightGBM] [Info] Start training from score 9.695890\n",
      "[LightGBM] [Info] Start training from score 9.699672\n",
      "[LightGBM] [Info] Start training from score 9.702203\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[50]\tcv_agg's valid l2: 3.44585 + 0.0395141\n",
      "[100]\tcv_agg's valid l2: 3.40995 + 0.0391893\n",
      "[150]\tcv_agg's valid l2: 3.38548 + 0.0423327\n",
      "[200]\tcv_agg's valid l2: 3.3714 + 0.0454136\n",
      "[250]\tcv_agg's valid l2: 3.36335 + 0.0473947\n",
      "[300]\tcv_agg's valid l2: 3.36171 + 0.046281\n",
      "[350]\tcv_agg's valid l2: 3.35905 + 0.0465428\n",
      "[400]\tcv_agg's valid l2: 3.35858 + 0.0466429\n",
      "[450]\tcv_agg's valid l2: 3.35847 + 0.0472582\n",
      "[500]\tcv_agg's valid l2: 3.36089 + 0.0471162\n",
      "[550]\tcv_agg's valid l2: 3.36303 + 0.0471983\n",
      "[600]\tcv_agg's valid l2: 3.36468 + 0.0466001\n",
      "[650]\tcv_agg's valid l2: 3.36799 + 0.048593\n",
      "[700]\tcv_agg's valid l2: 3.37195 + 0.0468747\n",
      "[750]\tcv_agg's valid l2: 3.37564 + 0.047686\n",
      "[800]\tcv_agg's valid l2: 3.37714 + 0.0482971\n",
      "[850]\tcv_agg's valid l2: 3.3809 + 0.0491176\n",
      "[900]\tcv_agg's valid l2: 3.38585 + 0.0490008\n",
      "[950]\tcv_agg's valid l2: 3.38999 + 0.0484619\n",
      "[1000]\tcv_agg's valid l2: 3.3932 + 0.0491224\n",
      "[1050]\tcv_agg's valid l2: 3.3958 + 0.0492732\n",
      "[1100]\tcv_agg's valid l2: 3.39932 + 0.0499175\n",
      "[1150]\tcv_agg's valid l2: 3.40465 + 0.0502228\n",
      "[1200]\tcv_agg's valid l2: 3.40902 + 0.0493526\n",
      "[1250]\tcv_agg's valid l2: 3.41252 + 0.0504942\n",
      "[1300]\tcv_agg's valid l2: 3.41614 + 0.04972\n",
      "[1350]\tcv_agg's valid l2: 3.41915 + 0.0500022\n",
      "[1400]\tcv_agg's valid l2: 3.42247 + 0.0497956\n",
      "[1450]\tcv_agg's valid l2: 3.42522 + 0.0501997\n",
      "[1500]\tcv_agg's valid l2: 3.4288 + 0.0513302\n",
      "[1550]\tcv_agg's valid l2: 3.43229 + 0.0525713\n",
      "[1600]\tcv_agg's valid l2: 3.43663 + 0.0514338\n",
      "[1650]\tcv_agg's valid l2: 3.43941 + 0.0525404\n",
      "[1700]\tcv_agg's valid l2: 3.44263 + 0.0523489\n",
      "[1750]\tcv_agg's valid l2: 3.44537 + 0.0521624\n",
      "[1800]\tcv_agg's valid l2: 3.44916 + 0.052125\n",
      "[1850]\tcv_agg's valid l2: 3.45252 + 0.0525847\n",
      "[1900]\tcv_agg's valid l2: 3.45603 + 0.0523963\n",
      "[1950]\tcv_agg's valid l2: 3.46084 + 0.0526322\n",
      "[2000]\tcv_agg's valid l2: 3.46409 + 0.0528487\n",
      "[2050]\tcv_agg's valid l2: 3.46715 + 0.0541432\n",
      "[2100]\tcv_agg's valid l2: 3.47138 + 0.0545972\n",
      "[2150]\tcv_agg's valid l2: 3.47396 + 0.0538189\n",
      "[2200]\tcv_agg's valid l2: 3.47716 + 0.0532258\n",
      "[2250]\tcv_agg's valid l2: 3.48075 + 0.0532821\n",
      "[2300]\tcv_agg's valid l2: 3.48386 + 0.053777\n",
      "[2350]\tcv_agg's valid l2: 3.48639 + 0.0540849\n",
      "Early stopping, best iteration is:\n",
      "[371]\tcv_agg's valid l2: 3.35818 + 0.0462679\n"
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(\n",
    "    params, \n",
    "    train_data, \n",
    "    10000, \n",
    "    nfold=4, \n",
    "    stratified=False,\n",
    "    callbacks=[lgb.log_evaluation(50)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70873845-483d-4764-a86e-fbd43b910bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_set\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCrossValidator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnfold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstratified\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minit_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeature_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Literal['auto']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Literal['auto']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfpreproc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_train_metric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_cvbooster\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCVBooster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Perform the cross-validation with given parameters.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "params : dict\n",
       "    Parameters for training. Values passed through ``params`` take precedence over those\n",
       "    supplied via arguments.\n",
       "train_set : Dataset\n",
       "    Data to be trained on.\n",
       "num_boost_round : int, optional (default=100)\n",
       "    Number of boosting iterations.\n",
       "folds : generator or iterator of (train_idx, test_idx) tuples, scikit-learn splitter object or None, optional (default=None)\n",
       "    If generator or iterator, it should yield the train and test indices for each fold.\n",
       "    If object, it should be one of the scikit-learn splitter classes\n",
       "    (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
       "    and have ``split`` method.\n",
       "    This argument has highest priority over other data split arguments.\n",
       "nfold : int, optional (default=5)\n",
       "    Number of folds in CV.\n",
       "stratified : bool, optional (default=True)\n",
       "    Whether to perform stratified sampling.\n",
       "shuffle : bool, optional (default=True)\n",
       "    Whether to shuffle before splitting data.\n",
       "metrics : str, list of str, or None, optional (default=None)\n",
       "    Evaluation metrics to be monitored while CV.\n",
       "    If not None, the metric in ``params`` will be overridden.\n",
       "feval : callable, list of callable, or None, optional (default=None)\n",
       "    Customized evaluation function.\n",
       "    Each evaluation function should accept two parameters: preds, eval_data,\n",
       "    and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
       "\n",
       "        preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "            The predicted values.\n",
       "            For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
       "            If custom objective function is used, predicted values are returned before any transformation,\n",
       "            e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
       "        eval_data : Dataset\n",
       "            A ``Dataset`` to evaluate.\n",
       "        eval_name : str\n",
       "            The name of evaluation function (without whitespace).\n",
       "        eval_result : float\n",
       "            The eval result.\n",
       "        is_higher_better : bool\n",
       "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
       "\n",
       "    To ignore the default metric corresponding to the used objective,\n",
       "    set ``metrics`` to the string ``\"None\"``.\n",
       "init_model : str, pathlib.Path, Booster or None, optional (default=None)\n",
       "    Filename of LightGBM model or Booster instance used for continue training.\n",
       "feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
       "    Feature names.\n",
       "    If 'auto' and data is pandas DataFrame, data columns names are used.\n",
       "categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
       "    Categorical features.\n",
       "    If list of int, interpreted as indices.\n",
       "    If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
       "    If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
       "    All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
       "    Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
       "    All negative values in categorical features will be treated as missing values.\n",
       "    The output cannot be monotonically constrained with respect to a categorical feature.\n",
       "    Floating point numbers in categorical features will be rounded towards 0.\n",
       "fpreproc : callable or None, optional (default=None)\n",
       "    Preprocessing function that takes (dtrain, dtest, params)\n",
       "    and returns transformed versions of those.\n",
       "seed : int, optional (default=0)\n",
       "    Seed used to generate the folds (passed to numpy.random.seed).\n",
       "callbacks : list of callable, or None, optional (default=None)\n",
       "    List of callback functions that are applied at each iteration.\n",
       "    See Callbacks in Python API for more information.\n",
       "eval_train_metric : bool, optional (default=False)\n",
       "    Whether to display the train metric in progress.\n",
       "    The score of the metric is calculated again after each training step, so there is some impact on performance.\n",
       "return_cvbooster : bool, optional (default=False)\n",
       "    Whether to return Booster models trained on each fold through ``CVBooster``.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "It should accept two parameters: preds, train_data and return (grad, hess).\n",
       "\n",
       "    preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The predicted values.\n",
       "        Predicted values are returned before any transformation,\n",
       "        e.g. they are raw margin instead of probability of positive class for binary task.\n",
       "    train_data : Dataset\n",
       "        The training dataset.\n",
       "    grad : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The value of the first order derivative (gradient) of the loss\n",
       "        with respect to the elements of preds for each sample point.\n",
       "    hess : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) of the loss\n",
       "        with respect to the elements of preds for each sample point.\n",
       "\n",
       "For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],\n",
       "and grad and hess should be returned in the same format.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "eval_results : dict\n",
       "    History of evaluation results of each metric.\n",
       "    The dictionary has the following format:\n",
       "    {'valid metric1-mean': [values], 'valid metric1-stdv': [values],\n",
       "    'valid metric2-mean': [values], 'valid metric2-stdv': [values],\n",
       "    ...}.\n",
       "    If ``return_cvbooster=True``, also returns trained boosters wrapped in a ``CVBooster`` object via ``cvbooster`` key.\n",
       "    If ``eval_train_metric=True``, also returns the train metric history.\n",
       "    In this case, the dictionary has the following format:\n",
       "    {'train metric1-mean': [values], 'valid metric1-mean': [values],\n",
       "    'train metric2-mean': [values], 'valid metric2-mean': [values],\n",
       "    ...}.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/py38/lib/python3.8/site-packages/lightgbm/engine.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.cv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21591241-91c5-467f-89b0-9ecd3891b05d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid l2-mean': [8.992646894243647,\n",
       "  8.026746016700486,\n",
       "  7.302455777876854,\n",
       "  6.6470727500251865,\n",
       "  6.11006886506589,\n",
       "  5.730305014728824,\n",
       "  5.352718983337658,\n",
       "  5.043853923258472,\n",
       "  4.8090055503195295,\n",
       "  4.611892330941165,\n",
       "  4.451106375743487,\n",
       "  4.309786390937407,\n",
       "  4.177757962802707,\n",
       "  4.069338233903398,\n",
       "  3.9871011516215797,\n",
       "  3.9187370599581426,\n",
       "  3.8624636036551303,\n",
       "  3.8045720009053214,\n",
       "  3.756773813984862,\n",
       "  3.7175369065868797,\n",
       "  3.681552603405449,\n",
       "  3.6517534960823097,\n",
       "  3.6293197102845265,\n",
       "  3.6065274902568087,\n",
       "  3.5869229977387613,\n",
       "  3.5702214368777065,\n",
       "  3.558782400865381,\n",
       "  3.5462944047922136,\n",
       "  3.536129532208845,\n",
       "  3.5250483032696844,\n",
       "  3.5158576030758826,\n",
       "  3.507398711638273,\n",
       "  3.500366069067079,\n",
       "  3.494985732209085,\n",
       "  3.490552099388813,\n",
       "  3.486584010569048,\n",
       "  3.4816149330473,\n",
       "  3.477184175817315,\n",
       "  3.473625987419077,\n",
       "  3.4701307029404633,\n",
       "  3.4665386036449295,\n",
       "  3.464777348726948,\n",
       "  3.4608744306031047,\n",
       "  3.4580070633330138,\n",
       "  3.455288688680137,\n",
       "  3.453313112953638,\n",
       "  3.451756515623269,\n",
       "  3.4499258733745934,\n",
       "  3.4488031255938334,\n",
       "  3.445847781182705,\n",
       "  3.444227125785753,\n",
       "  3.442320080875967,\n",
       "  3.440462640506883,\n",
       "  3.439056399662233,\n",
       "  3.4370354031591934,\n",
       "  3.4349352858070423,\n",
       "  3.43355158412468,\n",
       "  3.433374988073187,\n",
       "  3.4326453757991016,\n",
       "  3.431850125433548,\n",
       "  3.4308051942709117,\n",
       "  3.4303152772488765,\n",
       "  3.4292612500716655,\n",
       "  3.4282387125209666,\n",
       "  3.427537011549683,\n",
       "  3.427198860227509,\n",
       "  3.426338263528507,\n",
       "  3.4255436246326134,\n",
       "  3.424852589094887,\n",
       "  3.424563811392386,\n",
       "  3.4238670880217823,\n",
       "  3.423299795273761,\n",
       "  3.423071742858456,\n",
       "  3.422284299122122,\n",
       "  3.4217612256635888,\n",
       "  3.4209872181602634,\n",
       "  3.420694460706134,\n",
       "  3.4203211407022662,\n",
       "  3.4197848757572253,\n",
       "  3.419084135198303,\n",
       "  3.4184279592081834,\n",
       "  3.418033085798073,\n",
       "  3.4174955362022787,\n",
       "  3.417194514432169,\n",
       "  3.4166667744541908,\n",
       "  3.4165179901808878,\n",
       "  3.4155682126275653,\n",
       "  3.4152312362625383,\n",
       "  3.4141360665062623,\n",
       "  3.414037434586968,\n",
       "  3.413781326603822,\n",
       "  3.4133815288360987,\n",
       "  3.4123153403963875,\n",
       "  3.411874085580205,\n",
       "  3.4119344811073598,\n",
       "  3.4119685278861853,\n",
       "  3.4117781598321564,\n",
       "  3.4109167870380954,\n",
       "  3.4101919541672925,\n",
       "  3.409946730594825,\n",
       "  3.408623219258036,\n",
       "  3.407308493788549,\n",
       "  3.4067774745498687,\n",
       "  3.4060871571735283,\n",
       "  3.4053287230975267,\n",
       "  3.40489304308859,\n",
       "  3.404115156782833,\n",
       "  3.4037250818950477,\n",
       "  3.403070803759769,\n",
       "  3.402560760623167,\n",
       "  3.4024736146971857,\n",
       "  3.4022096031446285,\n",
       "  3.402081799257509,\n",
       "  3.4017141664965553,\n",
       "  3.401586981829867,\n",
       "  3.40066755042462,\n",
       "  3.400335113110775,\n",
       "  3.400272375474292,\n",
       "  3.399185419694838,\n",
       "  3.3988157290446708,\n",
       "  3.3980770290362647,\n",
       "  3.3976544772275825,\n",
       "  3.3971006040953977,\n",
       "  3.3960855709750803,\n",
       "  3.3960142176298653,\n",
       "  3.3953477827563527,\n",
       "  3.3950534647252706,\n",
       "  3.394679013692123,\n",
       "  3.3943622157675533,\n",
       "  3.3941806778157315,\n",
       "  3.394073885895337,\n",
       "  3.3937491040256145,\n",
       "  3.3925354947256534,\n",
       "  3.39227173075193,\n",
       "  3.39207447584063,\n",
       "  3.3914760678695393,\n",
       "  3.3913267649117813,\n",
       "  3.3910601157650033,\n",
       "  3.3906477268515403,\n",
       "  3.3895917446217387,\n",
       "  3.3889385076891823,\n",
       "  3.388770595239535,\n",
       "  3.3880726787440922,\n",
       "  3.38698399421923,\n",
       "  3.3870229650667607,\n",
       "  3.3868507865562285,\n",
       "  3.3866715534124676,\n",
       "  3.386211280379805,\n",
       "  3.386340161074222,\n",
       "  3.385475839856454,\n",
       "  3.3854830907665523,\n",
       "  3.3847070624951012,\n",
       "  3.3844267577575775,\n",
       "  3.383649524776012,\n",
       "  3.3824812169457545,\n",
       "  3.3822829805371684,\n",
       "  3.381965999468982,\n",
       "  3.3822626505512257,\n",
       "  3.3820936943117057,\n",
       "  3.3816186604630456,\n",
       "  3.3811322974909124,\n",
       "  3.381032188949542,\n",
       "  3.380378608014931,\n",
       "  3.3802129422951053,\n",
       "  3.3800732694278937,\n",
       "  3.3799772729214324,\n",
       "  3.3795642791718303,\n",
       "  3.379327659710122,\n",
       "  3.379309436523788,\n",
       "  3.3785351042519327,\n",
       "  3.3784410676521968,\n",
       "  3.378291230936871,\n",
       "  3.3776832015305662,\n",
       "  3.3776362390432677,\n",
       "  3.3773223684822935,\n",
       "  3.3771278603869783,\n",
       "  3.376933331503603,\n",
       "  3.376997294295545,\n",
       "  3.3765835431874,\n",
       "  3.3763941828165844,\n",
       "  3.3758813756167747,\n",
       "  3.37583177594572,\n",
       "  3.375131316340749,\n",
       "  3.3750316624934587,\n",
       "  3.3745384267515375,\n",
       "  3.374658802106658,\n",
       "  3.374355893420318,\n",
       "  3.3740838978005496,\n",
       "  3.3740089434551948,\n",
       "  3.373956434108236,\n",
       "  3.3741169973868663,\n",
       "  3.3735271648389626,\n",
       "  3.373329286729626,\n",
       "  3.3731281780005746,\n",
       "  3.3729234370410306,\n",
       "  3.3725068638781224,\n",
       "  3.3724406789528407,\n",
       "  3.371617463742877,\n",
       "  3.3715910139586196,\n",
       "  3.371400392485434,\n",
       "  3.371544808034067,\n",
       "  3.3716178372871397,\n",
       "  3.371627101401838,\n",
       "  3.3708854678144906,\n",
       "  3.369833964054964,\n",
       "  3.3694211640503133,\n",
       "  3.369222854398394,\n",
       "  3.368984841496005,\n",
       "  3.368651026441621,\n",
       "  3.368708066445025,\n",
       "  3.368511514277606,\n",
       "  3.3680698760312713,\n",
       "  3.367523650363239,\n",
       "  3.3673696621276017,\n",
       "  3.366942900962859,\n",
       "  3.366937531471326,\n",
       "  3.366864357931826,\n",
       "  3.3666533157522176,\n",
       "  3.3657812355585084,\n",
       "  3.366271846075887,\n",
       "  3.366100819144378,\n",
       "  3.365934382614407,\n",
       "  3.3661132779462366,\n",
       "  3.365615327248287,\n",
       "  3.3651276679466537,\n",
       "  3.365194861059877,\n",
       "  3.365152188253928,\n",
       "  3.3648329058280573,\n",
       "  3.3646485940264244,\n",
       "  3.3644713608793446,\n",
       "  3.363980295511368,\n",
       "  3.363863747254726,\n",
       "  3.364011429866798,\n",
       "  3.3641344684395698,\n",
       "  3.363961754670399,\n",
       "  3.363750130844714,\n",
       "  3.3639405057014393,\n",
       "  3.363826668844203,\n",
       "  3.364011354251789,\n",
       "  3.363870600867038,\n",
       "  3.364152005288882,\n",
       "  3.3641660217109974,\n",
       "  3.364050609526191,\n",
       "  3.363698615223977,\n",
       "  3.363634405518451,\n",
       "  3.3637602885071396,\n",
       "  3.3634973981510905,\n",
       "  3.3633844441294602,\n",
       "  3.3632698631958764,\n",
       "  3.3633520736520897,\n",
       "  3.3632093596659667,\n",
       "  3.3632667433988255,\n",
       "  3.363204928005594,\n",
       "  3.3630520473411267,\n",
       "  3.363075983894603,\n",
       "  3.3629107748515255,\n",
       "  3.3627104008002284,\n",
       "  3.362856215831017,\n",
       "  3.3628383362527776,\n",
       "  3.362735533532342,\n",
       "  3.3629054497047446,\n",
       "  3.3628126545249706,\n",
       "  3.3628954401333093,\n",
       "  3.3627460396529454,\n",
       "  3.3628482353901843,\n",
       "  3.362437338571043,\n",
       "  3.36251870026982,\n",
       "  3.36225732796994,\n",
       "  3.3624129549970063,\n",
       "  3.362159025262005,\n",
       "  3.361898931124504,\n",
       "  3.3617488471512247,\n",
       "  3.3619543906468543,\n",
       "  3.3614979991119833,\n",
       "  3.3615591933816806,\n",
       "  3.3618286829998074,\n",
       "  3.3620006456471936,\n",
       "  3.362088013983594,\n",
       "  3.361958138899417,\n",
       "  3.3621352973219367,\n",
       "  3.3621764625354658,\n",
       "  3.3622741284010336,\n",
       "  3.3623704853089222,\n",
       "  3.3624320396542657,\n",
       "  3.3621865726398914,\n",
       "  3.362275619953685,\n",
       "  3.362180900665415,\n",
       "  3.3623487523707416,\n",
       "  3.3624334910588267,\n",
       "  3.3625026954286246,\n",
       "  3.362170966161642,\n",
       "  3.3622009541826237,\n",
       "  3.3624163824842217,\n",
       "  3.362499328103323,\n",
       "  3.362399480192635,\n",
       "  3.3621277871523363,\n",
       "  3.3620240574096476,\n",
       "  3.3620459805865535,\n",
       "  3.362074380935909,\n",
       "  3.361709776025491,\n",
       "  3.3614106882158428,\n",
       "  3.3608381505337976,\n",
       "  3.360842169744071,\n",
       "  3.360865815546536,\n",
       "  3.36081907430568,\n",
       "  3.360680134080965,\n",
       "  3.360770644006514,\n",
       "  3.360778550760168,\n",
       "  3.360742642616775,\n",
       "  3.3603929361823313,\n",
       "  3.3603065846867324,\n",
       "  3.36040690395905,\n",
       "  3.360483962186896,\n",
       "  3.3604013525138905,\n",
       "  3.360492938012525,\n",
       "  3.360285091677108,\n",
       "  3.3600974356697537,\n",
       "  3.359749927585432,\n",
       "  3.359902541496277,\n",
       "  3.35958995920934,\n",
       "  3.359551152689834,\n",
       "  3.3594219576338205,\n",
       "  3.35902724160362,\n",
       "  3.359049514722477,\n",
       "  3.3592555525148926,\n",
       "  3.3591322980982445,\n",
       "  3.359266430570356,\n",
       "  3.3591976917136943,\n",
       "  3.3591060759467046,\n",
       "  3.359087376229166,\n",
       "  3.359013640202105,\n",
       "  3.3590696954573245,\n",
       "  3.359493631426668,\n",
       "  3.3594079171380997,\n",
       "  3.359394276187121,\n",
       "  3.359198432941748,\n",
       "  3.359076281230049,\n",
       "  3.358980753991237,\n",
       "  3.3590638752576685,\n",
       "  3.3588562755514593,\n",
       "  3.3588825397391826,\n",
       "  3.3590641052550323,\n",
       "  3.3591057715345567,\n",
       "  3.3590784060154384,\n",
       "  3.3590159661418952,\n",
       "  3.359212178926363,\n",
       "  3.359064776682415,\n",
       "  3.3591044542818453,\n",
       "  3.3588241832244226,\n",
       "  3.359050723721815,\n",
       "  3.3593399157179067,\n",
       "  3.3592080761855967,\n",
       "  3.3592320065222667,\n",
       "  3.3590840491361864,\n",
       "  3.3592154798042477,\n",
       "  3.3588346431596374,\n",
       "  3.358637558786823,\n",
       "  3.358644895399679,\n",
       "  3.35864077948926,\n",
       "  3.358491266560445,\n",
       "  3.3588528985334123,\n",
       "  3.358902370986312,\n",
       "  3.3588589148038532,\n",
       "  3.358507318202495,\n",
       "  3.358820778690304,\n",
       "  3.358669724912044,\n",
       "  3.358842240304462,\n",
       "  3.3586608323075238,\n",
       "  3.358656760325874,\n",
       "  3.358421232545582,\n",
       "  3.358184715598005],\n",
       " 'valid l2-stdv': [0.1550108295121556,\n",
       "  0.14517624371353005,\n",
       "  0.13697658153360145,\n",
       "  0.12950714647704437,\n",
       "  0.12197321468729669,\n",
       "  0.11576915678614653,\n",
       "  0.10849370739080982,\n",
       "  0.10238399963332177,\n",
       "  0.09879051601967248,\n",
       "  0.09366182550053286,\n",
       "  0.08795340521274705,\n",
       "  0.08062074826133614,\n",
       "  0.07712657351389093,\n",
       "  0.0730494882651897,\n",
       "  0.06899994955774477,\n",
       "  0.06598157581621782,\n",
       "  0.06239333412059785,\n",
       "  0.058970766981576286,\n",
       "  0.05478510231257004,\n",
       "  0.05316654604550454,\n",
       "  0.05164141732725459,\n",
       "  0.048990879271392,\n",
       "  0.04849326479247391,\n",
       "  0.04686810420322165,\n",
       "  0.045715477249003635,\n",
       "  0.045020641080894264,\n",
       "  0.043941172508881306,\n",
       "  0.04327195082608761,\n",
       "  0.04256208893853002,\n",
       "  0.04045396551529446,\n",
       "  0.03979681945128208,\n",
       "  0.03881508313938947,\n",
       "  0.03872052663125571,\n",
       "  0.038879395764896824,\n",
       "  0.03865614384705018,\n",
       "  0.0378908187727519,\n",
       "  0.035967969841839954,\n",
       "  0.037032352825748474,\n",
       "  0.03751063771482596,\n",
       "  0.037457907651414976,\n",
       "  0.037713895471742746,\n",
       "  0.03803389259559402,\n",
       "  0.038569199899358426,\n",
       "  0.03921737571452474,\n",
       "  0.038673155534759286,\n",
       "  0.03963421503521901,\n",
       "  0.03999340342233149,\n",
       "  0.039486045283256895,\n",
       "  0.039453992099977075,\n",
       "  0.03951409922731697,\n",
       "  0.03962470910782753,\n",
       "  0.039927233891589003,\n",
       "  0.03988592579738011,\n",
       "  0.039621853737895396,\n",
       "  0.03898859623669153,\n",
       "  0.03912314501256373,\n",
       "  0.03885535662920322,\n",
       "  0.038713808569020534,\n",
       "  0.038321668008773103,\n",
       "  0.038320821101918146,\n",
       "  0.03894492201162131,\n",
       "  0.038768921363801126,\n",
       "  0.03858556118255112,\n",
       "  0.038098383869495045,\n",
       "  0.03811339118160214,\n",
       "  0.038645153907794834,\n",
       "  0.03851168982294999,\n",
       "  0.038465352593851115,\n",
       "  0.03937957161479315,\n",
       "  0.039151815352873584,\n",
       "  0.03891393539638854,\n",
       "  0.03858958530888936,\n",
       "  0.03865509959037458,\n",
       "  0.03876069752416921,\n",
       "  0.03948262270529708,\n",
       "  0.03929008914938459,\n",
       "  0.03957518468624698,\n",
       "  0.039679413499638536,\n",
       "  0.0395895158811606,\n",
       "  0.03969384455672748,\n",
       "  0.03914166500725535,\n",
       "  0.039403090322449735,\n",
       "  0.03933865176946221,\n",
       "  0.03922314288706563,\n",
       "  0.03899823710653942,\n",
       "  0.03892701791568112,\n",
       "  0.03881784735106537,\n",
       "  0.039100479341086576,\n",
       "  0.039227247968092675,\n",
       "  0.03907958881913901,\n",
       "  0.038979005150253945,\n",
       "  0.03892894722532563,\n",
       "  0.03928760460800825,\n",
       "  0.039488490361644264,\n",
       "  0.03946380909605255,\n",
       "  0.03952297211738072,\n",
       "  0.039374532288210425,\n",
       "  0.038815337502345656,\n",
       "  0.03915928051263887,\n",
       "  0.039189299587766194,\n",
       "  0.03934436323460066,\n",
       "  0.03911440034275061,\n",
       "  0.038669657041547206,\n",
       "  0.038580620087652645,\n",
       "  0.03886314657897184,\n",
       "  0.03880438753581217,\n",
       "  0.03892426867822664,\n",
       "  0.0390690498016691,\n",
       "  0.03947867465148756,\n",
       "  0.03942498723663961,\n",
       "  0.03986070708802433,\n",
       "  0.03977312963299684,\n",
       "  0.03965635837176031,\n",
       "  0.039595301994340984,\n",
       "  0.0396631152564766,\n",
       "  0.03977858580948332,\n",
       "  0.03980620052933118,\n",
       "  0.03972887546978183,\n",
       "  0.04013061478925662,\n",
       "  0.04033532808195474,\n",
       "  0.04015806724307457,\n",
       "  0.040506157689640526,\n",
       "  0.04076707041158073,\n",
       "  0.040546464012733964,\n",
       "  0.040329185290892036,\n",
       "  0.0403800908293503,\n",
       "  0.04064813816046765,\n",
       "  0.04096838466502177,\n",
       "  0.041057200349545374,\n",
       "  0.04101077970215563,\n",
       "  0.040954179651281473,\n",
       "  0.04081095730036045,\n",
       "  0.03997344343547854,\n",
       "  0.03978999482040534,\n",
       "  0.03964151717090593,\n",
       "  0.04021613858246514,\n",
       "  0.04079690230120987,\n",
       "  0.040437644924495204,\n",
       "  0.04042000865455462,\n",
       "  0.04072499434804393,\n",
       "  0.04119024636562181,\n",
       "  0.041496635862181844,\n",
       "  0.04124400902121919,\n",
       "  0.04142223469997655,\n",
       "  0.04160718669117492,\n",
       "  0.041762212625405984,\n",
       "  0.04186186740100406,\n",
       "  0.04273097798927882,\n",
       "  0.04282918907245801,\n",
       "  0.042332749502891204,\n",
       "  0.042388342598666355,\n",
       "  0.04245285045459065,\n",
       "  0.042805887130894525,\n",
       "  0.04322283618239339,\n",
       "  0.04317741756560171,\n",
       "  0.043210305693723326,\n",
       "  0.04365810175678863,\n",
       "  0.04389811742015894,\n",
       "  0.04402885086487409,\n",
       "  0.043817837794042344,\n",
       "  0.043777546466988504,\n",
       "  0.04355040185774843,\n",
       "  0.04361523760331999,\n",
       "  0.04381965365306665,\n",
       "  0.04436979345499728,\n",
       "  0.04417111020991926,\n",
       "  0.0443931148626131,\n",
       "  0.04483811620203757,\n",
       "  0.04495499022652264,\n",
       "  0.04475085907103397,\n",
       "  0.04483623487832775,\n",
       "  0.045010858419053966,\n",
       "  0.045101608166273184,\n",
       "  0.045142855990634945,\n",
       "  0.04493215350944481,\n",
       "  0.04480495431675898,\n",
       "  0.04476004557121421,\n",
       "  0.04481831530023035,\n",
       "  0.04491510226994118,\n",
       "  0.04508633730942009,\n",
       "  0.04536624043307344,\n",
       "  0.04550680215409579,\n",
       "  0.04549562783093026,\n",
       "  0.04529287434628619,\n",
       "  0.04510961618209874,\n",
       "  0.044807680379187136,\n",
       "  0.045193784346301204,\n",
       "  0.04505225958383522,\n",
       "  0.04519082210195148,\n",
       "  0.04526173325255401,\n",
       "  0.04539505647381642,\n",
       "  0.04539344712176005,\n",
       "  0.04544705170100814,\n",
       "  0.04573191866717512,\n",
       "  0.045467047584817184,\n",
       "  0.04538664931105333,\n",
       "  0.04557879284816968,\n",
       "  0.04562284533934929,\n",
       "  0.04543017389011957,\n",
       "  0.04541355845364972,\n",
       "  0.04542899912520139,\n",
       "  0.045273300290635234,\n",
       "  0.045323119653561665,\n",
       "  0.04511527359916458,\n",
       "  0.04452303763830833,\n",
       "  0.04466324322687897,\n",
       "  0.04455074659077464,\n",
       "  0.045070686786905366,\n",
       "  0.04483721632941319,\n",
       "  0.045147303204621174,\n",
       "  0.04493641977743985,\n",
       "  0.044821272838657576,\n",
       "  0.044933719948095134,\n",
       "  0.04504080058227561,\n",
       "  0.044881471391567236,\n",
       "  0.04497051014102931,\n",
       "  0.044718151271628266,\n",
       "  0.04467120742234668,\n",
       "  0.044299767143724085,\n",
       "  0.04457494009078003,\n",
       "  0.04460875955325747,\n",
       "  0.04469355229759978,\n",
       "  0.04478896369964463,\n",
       "  0.044742324670338306,\n",
       "  0.04490317104548765,\n",
       "  0.044609573665546576,\n",
       "  0.04466557570694655,\n",
       "  0.0448203537261606,\n",
       "  0.044816654725256484,\n",
       "  0.044913295752112344,\n",
       "  0.045177968495355755,\n",
       "  0.04519613527908019,\n",
       "  0.04553689399141754,\n",
       "  0.04548515877536965,\n",
       "  0.04531491863651426,\n",
       "  0.04589312624379465,\n",
       "  0.04614267082200394,\n",
       "  0.04617728341759672,\n",
       "  0.04615586690220525,\n",
       "  0.0465745296397993,\n",
       "  0.046783420830516856,\n",
       "  0.04673603909331238,\n",
       "  0.046907637140147646,\n",
       "  0.04692748264384504,\n",
       "  0.04670963439805111,\n",
       "  0.04653264114761637,\n",
       "  0.04659931181449707,\n",
       "  0.046872409431944984,\n",
       "  0.04712680760238558,\n",
       "  0.04739470014918577,\n",
       "  0.04763562943486083,\n",
       "  0.04746814853850376,\n",
       "  0.04764401737856903,\n",
       "  0.04750423177409733,\n",
       "  0.047588026096688246,\n",
       "  0.04741021485264605,\n",
       "  0.0472615782998077,\n",
       "  0.046999528722415466,\n",
       "  0.04660106247366264,\n",
       "  0.046644027960348576,\n",
       "  0.046902866911811565,\n",
       "  0.046898231099033245,\n",
       "  0.04668856719237025,\n",
       "  0.046904273112573336,\n",
       "  0.04705256317759317,\n",
       "  0.0470427455008161,\n",
       "  0.047133097613679724,\n",
       "  0.04711479163287639,\n",
       "  0.04715158077345347,\n",
       "  0.04683295708695401,\n",
       "  0.04676292773895043,\n",
       "  0.046610668621938044,\n",
       "  0.04647008953447736,\n",
       "  0.04658477314744949,\n",
       "  0.0467116369186044,\n",
       "  0.04660738592472849,\n",
       "  0.04662728350872656,\n",
       "  0.046667483750098035,\n",
       "  0.04660882383498135,\n",
       "  0.04641151877518362,\n",
       "  0.04622806427478102,\n",
       "  0.04631093276215593,\n",
       "  0.04637225687040571,\n",
       "  0.04639278399641634,\n",
       "  0.04621681863006015,\n",
       "  0.046566587619119804,\n",
       "  0.04619260234260636,\n",
       "  0.04634379460913833,\n",
       "  0.04612306035329995,\n",
       "  0.046214935784498846,\n",
       "  0.046211791806766385,\n",
       "  0.04627899402105684,\n",
       "  0.04638251429244811,\n",
       "  0.046288160599926576,\n",
       "  0.04637662662987883,\n",
       "  0.04669614466086803,\n",
       "  0.04625565991404597,\n",
       "  0.04671747114919785,\n",
       "  0.04642392129126539,\n",
       "  0.04628098763926943,\n",
       "  0.04612484858611959,\n",
       "  0.04603169923637453,\n",
       "  0.04599674297414551,\n",
       "  0.04607183380050021,\n",
       "  0.046065647961697646,\n",
       "  0.046036512595180205,\n",
       "  0.04622716850298949,\n",
       "  0.046326880499548286,\n",
       "  0.04657809501504192,\n",
       "  0.046533121119288645,\n",
       "  0.04643958512947866,\n",
       "  0.046254446271828314,\n",
       "  0.04617707139832531,\n",
       "  0.04612445296175573,\n",
       "  0.046085718354247046,\n",
       "  0.04605533186567887,\n",
       "  0.04647750559625282,\n",
       "  0.046506807831646506,\n",
       "  0.04666598446426094,\n",
       "  0.04630541888975869,\n",
       "  0.04617118662762599,\n",
       "  0.04603035939844205,\n",
       "  0.04614389329165771,\n",
       "  0.046004515629207314,\n",
       "  0.045721211634543645,\n",
       "  0.04559943716494059,\n",
       "  0.0457909289955826,\n",
       "  0.046167010874971035,\n",
       "  0.04615640721332783,\n",
       "  0.04598728998649446,\n",
       "  0.04601029394255493,\n",
       "  0.0462320495979547,\n",
       "  0.04594123714841168,\n",
       "  0.04576948945190312,\n",
       "  0.04577528758882514,\n",
       "  0.04588891180563246,\n",
       "  0.046108546446449024,\n",
       "  0.046263213508762814,\n",
       "  0.0463788075423107,\n",
       "  0.04612364488352214,\n",
       "  0.046244391641351516,\n",
       "  0.04609211504937068,\n",
       "  0.046173903146271476,\n",
       "  0.04631468100863697,\n",
       "  0.04642022998100813,\n",
       "  0.046554329760116114,\n",
       "  0.046315293824991347,\n",
       "  0.04652625483725817,\n",
       "  0.04655884479393978,\n",
       "  0.046542831905851435,\n",
       "  0.04657038837527933,\n",
       "  0.04664406041133687,\n",
       "  0.04677865437657206,\n",
       "  0.04689022230648444,\n",
       "  0.046582828049859304,\n",
       "  0.04638169992725202,\n",
       "  0.04635055657658372,\n",
       "  0.04604705484831065,\n",
       "  0.04602549789943579,\n",
       "  0.04605462949379826,\n",
       "  0.04614466007364483,\n",
       "  0.04612805438231683,\n",
       "  0.045768453382924824,\n",
       "  0.04584603546876145,\n",
       "  0.04621063982610473,\n",
       "  0.04631993139287208,\n",
       "  0.04660903969946037,\n",
       "  0.04657437978364431,\n",
       "  0.046710363662174514,\n",
       "  0.0464887440356694,\n",
       "  0.046267935202406824]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "161fc538-2f1f-463d-b1e2-30c6c4310fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_cv['valid l2-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a6cb3a-f66a-4105-834a-a82c75e7f228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lgb_cv['valid l2-mean'][:1000])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef4b2770-e97e-41c5-8a8f-96ff0b0f2603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1590\n",
      "[LightGBM] [Info] Number of data points in the train set: 90615, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 9.696794\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params, train_data, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cd78ab9-57f3-4f9f-98cb-a83d32d4355f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90615</td>\n",
       "      <td>M</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.155</td>\n",
       "      <td>1.2380</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.3005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90616</td>\n",
       "      <td>M</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90617</td>\n",
       "      <td>M</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90618</td>\n",
       "      <td>M</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90619</td>\n",
       "      <td>I</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
       "0  90615   M   0.645     0.475   0.155        1.2380          0.6185   \n",
       "1  90616   M   0.580     0.460   0.160        0.9830          0.4785   \n",
       "2  90617   M   0.560     0.420   0.140        0.8395          0.3525   \n",
       "3  90618   M   0.570     0.490   0.145        0.8740          0.3525   \n",
       "4  90619   I   0.415     0.325   0.110        0.3580          0.1575   \n",
       "\n",
       "   Whole weight.2  Shell weight  \n",
       "0          0.3125        0.3005  \n",
       "1          0.2195        0.2750  \n",
       "2          0.1845        0.2405  \n",
       "3          0.1865        0.2350  \n",
       "4          0.0670        0.1050  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4f80976-7170-49a5-aff8-12a309adccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Sex_code'] = test_df.Sex.map(Sex2code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcc21a8a-626d-4c81-b3be-ad356432e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_df[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e3750e6-8bbf-4b81-8e72-402eac7012d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Rings'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb50b3-0e2c-41ab-a923-e5084277e6a5",
   "metadata": {},
   "source": [
    "## 提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "690ee020-0e9f-49ae-b515-110871860798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7764975-c23f-4293-aadb-169797d87718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90615</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90616</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90617</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90618</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90619</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Rings\n",
       "0  90615     10\n",
       "1  90616     10\n",
       "2  90617     10\n",
       "3  90618     10\n",
       "4  90619     10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "796113f9-7756-4ecf-8627-25edf4dfd367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub_df['id'] == test_df['id']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "828e4a57-cbfa-4583-9724-a5485f0a4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'Rings']\n",
    "test_df[cols].to_csv('simple_lgb_iter400.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b823157-54dd-44ab-8842-f88955206f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Rings\n",
      "90615,9.5980866867818\n",
      "90616,9.373612869946278\n",
      "90617,10.025133025264868\n",
      "90618,10.005288110050207\n",
      "90619,7.55387503516864\n",
      "90620,9.446224644208044\n",
      "90621,10.704996517741126\n",
      "90622,6.310706393807703\n",
      "90623,8.047817413929062\n"
     ]
    }
   ],
   "source": [
    "!head simple_lgb_iter400.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe0bc874-a927-4d1f-807d-071752f1bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Rings\n",
      "90615,10\n",
      "90616,10\n",
      "90617,10\n",
      "90618,10\n",
      "90619,10\n",
      "90620,10\n",
      "90621,10\n",
      "90622,10\n",
      "90623,10\n"
     ]
    }
   ],
   "source": [
    "!head ../input/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f98b90b8-3482-42d3-bd95-959c11f8ee28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_set\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCrossValidator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnfold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstratified\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minit_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeature_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Literal['auto']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Literal['auto']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfpreproc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meval_train_metric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_cvbooster\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCVBooster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Perform the cross-validation with given parameters.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "params : dict\n",
       "    Parameters for training. Values passed through ``params`` take precedence over those\n",
       "    supplied via arguments.\n",
       "train_set : Dataset\n",
       "    Data to be trained on.\n",
       "num_boost_round : int, optional (default=100)\n",
       "    Number of boosting iterations.\n",
       "folds : generator or iterator of (train_idx, test_idx) tuples, scikit-learn splitter object or None, optional (default=None)\n",
       "    If generator or iterator, it should yield the train and test indices for each fold.\n",
       "    If object, it should be one of the scikit-learn splitter classes\n",
       "    (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
       "    and have ``split`` method.\n",
       "    This argument has highest priority over other data split arguments.\n",
       "nfold : int, optional (default=5)\n",
       "    Number of folds in CV.\n",
       "stratified : bool, optional (default=True)\n",
       "    Whether to perform stratified sampling.\n",
       "shuffle : bool, optional (default=True)\n",
       "    Whether to shuffle before splitting data.\n",
       "metrics : str, list of str, or None, optional (default=None)\n",
       "    Evaluation metrics to be monitored while CV.\n",
       "    If not None, the metric in ``params`` will be overridden.\n",
       "feval : callable, list of callable, or None, optional (default=None)\n",
       "    Customized evaluation function.\n",
       "    Each evaluation function should accept two parameters: preds, eval_data,\n",
       "    and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
       "\n",
       "        preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "            The predicted values.\n",
       "            For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
       "            If custom objective function is used, predicted values are returned before any transformation,\n",
       "            e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
       "        eval_data : Dataset\n",
       "            A ``Dataset`` to evaluate.\n",
       "        eval_name : str\n",
       "            The name of evaluation function (without whitespace).\n",
       "        eval_result : float\n",
       "            The eval result.\n",
       "        is_higher_better : bool\n",
       "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
       "\n",
       "    To ignore the default metric corresponding to the used objective,\n",
       "    set ``metrics`` to the string ``\"None\"``.\n",
       "init_model : str, pathlib.Path, Booster or None, optional (default=None)\n",
       "    Filename of LightGBM model or Booster instance used for continue training.\n",
       "feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
       "    Feature names.\n",
       "    If 'auto' and data is pandas DataFrame, data columns names are used.\n",
       "categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
       "    Categorical features.\n",
       "    If list of int, interpreted as indices.\n",
       "    If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
       "    If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
       "    All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
       "    Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
       "    All negative values in categorical features will be treated as missing values.\n",
       "    The output cannot be monotonically constrained with respect to a categorical feature.\n",
       "    Floating point numbers in categorical features will be rounded towards 0.\n",
       "fpreproc : callable or None, optional (default=None)\n",
       "    Preprocessing function that takes (dtrain, dtest, params)\n",
       "    and returns transformed versions of those.\n",
       "seed : int, optional (default=0)\n",
       "    Seed used to generate the folds (passed to numpy.random.seed).\n",
       "callbacks : list of callable, or None, optional (default=None)\n",
       "    List of callback functions that are applied at each iteration.\n",
       "    See Callbacks in Python API for more information.\n",
       "eval_train_metric : bool, optional (default=False)\n",
       "    Whether to display the train metric in progress.\n",
       "    The score of the metric is calculated again after each training step, so there is some impact on performance.\n",
       "return_cvbooster : bool, optional (default=False)\n",
       "    Whether to return Booster models trained on each fold through ``CVBooster``.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "It should accept two parameters: preds, train_data and return (grad, hess).\n",
       "\n",
       "    preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The predicted values.\n",
       "        Predicted values are returned before any transformation,\n",
       "        e.g. they are raw margin instead of probability of positive class for binary task.\n",
       "    train_data : Dataset\n",
       "        The training dataset.\n",
       "    grad : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The value of the first order derivative (gradient) of the loss\n",
       "        with respect to the elements of preds for each sample point.\n",
       "    hess : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) of the loss\n",
       "        with respect to the elements of preds for each sample point.\n",
       "\n",
       "For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],\n",
       "and grad and hess should be returned in the same format.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "eval_results : dict\n",
       "    History of evaluation results of each metric.\n",
       "    The dictionary has the following format:\n",
       "    {'valid metric1-mean': [values], 'valid metric1-stdv': [values],\n",
       "    'valid metric2-mean': [values], 'valid metric2-stdv': [values],\n",
       "    ...}.\n",
       "    If ``return_cvbooster=True``, also returns trained boosters wrapped in a ``CVBooster`` object via ``cvbooster`` key.\n",
       "    If ``eval_train_metric=True``, also returns the train metric history.\n",
       "    In this case, the dictionary has the following format:\n",
       "    {'train metric1-mean': [values], 'valid metric1-mean': [values],\n",
       "    'train metric2-mean': [values], 'valid metric2-mean': [values],\n",
       "    ...}.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/py38/lib/python3.8/site-packages/lightgbm/engine.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.cv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b6f23a4-d153-4e74-82e1-ea7eae923fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3.0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e33d742b-2118-4698-9b53-bbab215792d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_set\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalid_sets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalid_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minit_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeature_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Literal['auto']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Literal['auto']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_training_booster\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Perform the training with given parameters.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "params : dict\n",
       "    Parameters for training. Values passed through ``params`` take precedence over those\n",
       "    supplied via arguments.\n",
       "train_set : Dataset\n",
       "    Data to be trained on.\n",
       "num_boost_round : int, optional (default=100)\n",
       "    Number of boosting iterations.\n",
       "valid_sets : list of Dataset, or None, optional (default=None)\n",
       "    List of data to be evaluated on during training.\n",
       "valid_names : list of str, or None, optional (default=None)\n",
       "    Names of ``valid_sets``.\n",
       "feval : callable, list of callable, or None, optional (default=None)\n",
       "    Customized evaluation function.\n",
       "    Each evaluation function should accept two parameters: preds, eval_data,\n",
       "    and return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
       "\n",
       "        preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "            The predicted values.\n",
       "            For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].\n",
       "            If custom objective function is used, predicted values are returned before any transformation,\n",
       "            e.g. they are raw margin instead of probability of positive class for binary task in this case.\n",
       "        eval_data : Dataset\n",
       "            A ``Dataset`` to evaluate.\n",
       "        eval_name : str\n",
       "            The name of evaluation function (without whitespaces).\n",
       "        eval_result : float\n",
       "            The eval result.\n",
       "        is_higher_better : bool\n",
       "            Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
       "\n",
       "    To ignore the default metric corresponding to the used objective,\n",
       "    set the ``metric`` parameter to the string ``\"None\"`` in ``params``.\n",
       "init_model : str, pathlib.Path, Booster or None, optional (default=None)\n",
       "    Filename of LightGBM model or Booster instance used for continue training.\n",
       "feature_name : list of str, or 'auto', optional (default=\"auto\")\n",
       "    Feature names.\n",
       "    If 'auto' and data is pandas DataFrame, data columns names are used.\n",
       "categorical_feature : list of str or int, or 'auto', optional (default=\"auto\")\n",
       "    Categorical features.\n",
       "    If list of int, interpreted as indices.\n",
       "    If list of str, interpreted as feature names (need to specify ``feature_name`` as well).\n",
       "    If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
       "    All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).\n",
       "    Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
       "    All negative values in categorical features will be treated as missing values.\n",
       "    The output cannot be monotonically constrained with respect to a categorical feature.\n",
       "    Floating point numbers in categorical features will be rounded towards 0.\n",
       "keep_training_booster : bool, optional (default=False)\n",
       "    Whether the returned Booster will be used to keep training.\n",
       "    If False, the returned value will be converted into _InnerPredictor before returning.\n",
       "    This means you won't be able to use ``eval``, ``eval_train`` or ``eval_valid`` methods of the returned Booster.\n",
       "    When your model is very large and cause the memory error,\n",
       "    you can try to set this param to ``True`` to avoid the model conversion performed during the internal call of ``model_to_string``.\n",
       "    You can still use _InnerPredictor as ``init_model`` for future continue training.\n",
       "callbacks : list of callable, or None, optional (default=None)\n",
       "    List of callback functions that are applied at each iteration.\n",
       "    See Callbacks in Python API for more information.\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "It should accept two parameters: preds, train_data and return (grad, hess).\n",
       "\n",
       "    preds : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The predicted values.\n",
       "        Predicted values are returned before any transformation,\n",
       "        e.g. they are raw margin instead of probability of positive class for binary task.\n",
       "    train_data : Dataset\n",
       "        The training dataset.\n",
       "    grad : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The value of the first order derivative (gradient) of the loss\n",
       "        with respect to the elements of preds for each sample point.\n",
       "    hess : numpy 1-D array or numpy 2-D array (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) of the loss\n",
       "        with respect to the elements of preds for each sample point.\n",
       "\n",
       "For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],\n",
       "and grad and hess should be returned in the same format.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "booster : Booster\n",
       "    The trained Booster model.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/py38/lib/python3.8/site-packages/lightgbm/engine.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22713108-105b-4dc5-9436-5394dd3e87ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
