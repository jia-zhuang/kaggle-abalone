{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16112045-1309-4f82-99dd-0fa383445103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866ea0e-bf79-4489-a89d-4d8abd5c3f8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c6d48b-c8f3-45dd-8139-f1257af023c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4adbb6aa-2a6a-4a04-a114-245495a16cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_cols = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', 'Whole weight.2', 'Shell weight', 'Rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28edacd8-25cd-4074-b2fe-815161c59c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_df = pd.read_csv('../input/abalone.data', names=abalone_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a54dc0-b7db-4b61-b9dd-84b229d23625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4177"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff08c06-55e4-4e4f-973b-51acce0cad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d9816d-e18d-48ad-b4d9-87f62612954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
       "0   0   F   0.550     0.430   0.150        0.7715          0.3285   \n",
       "1   1   F   0.630     0.490   0.145        1.1300          0.4580   \n",
       "2   2   I   0.160     0.110   0.025        0.0210          0.0055   \n",
       "3   3   M   0.595     0.475   0.150        0.9145          0.3755   \n",
       "4   4   I   0.555     0.425   0.130        0.7820          0.3695   \n",
       "\n",
       "   Whole weight.2  Shell weight  Rings  \n",
       "0          0.1465        0.2400     11  \n",
       "1          0.2765        0.3200     11  \n",
       "2          0.0030        0.0050      6  \n",
       "3          0.2055        0.2500     10  \n",
       "4          0.1600        0.1975      9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400d880-3c9e-4e79-89ff-dd3526b65926",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47c8078-cc66-4c3b-b3c3-b580b6bc3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df = pd.concat([train_df, ext_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664e5bb3-df76-43cb-923f-00d38105b811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94792"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums_train = train_df.shape[0] + ext_df.shape[0]\n",
    "nums_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ced7a5b-608b-4a0d-97ed-20bbb78cb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = com_df.index[:nums_train]\n",
    "test_idx = com_df.index[nums_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a99065-331d-48bd-8a81-cea4dfb52d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94792, 60411)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape[0], test_idx.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c96b3-2cfc-46df-b585-574ddf2fb91a",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161ac624-9e6e-415e-bf94-d02e2b293a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex2code = {'I': 0, 'M': 1, 'F': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55cf95a1-b845-45d3-b41f-42d10083853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_df['Sex_code'] = com_df['Sex'].map(Sex2code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "150eedd6-2c46-419d-8b8a-837ba159500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
       "0  0.0   F   0.550     0.430   0.150        0.7715          0.3285   \n",
       "1  1.0   F   0.630     0.490   0.145        1.1300          0.4580   \n",
       "2  2.0   I   0.160     0.110   0.025        0.0210          0.0055   \n",
       "3  3.0   M   0.595     0.475   0.150        0.9145          0.3755   \n",
       "4  4.0   I   0.555     0.425   0.130        0.7820          0.3695   \n",
       "\n",
       "   Whole weight.2  Shell weight  Rings  Sex_code  \n",
       "0          0.1465        0.2400   11.0         2  \n",
       "1          0.2765        0.3200   11.0         2  \n",
       "2          0.0030        0.0050    6.0         0  \n",
       "3          0.2055        0.2500   10.0         1  \n",
       "4          0.1600        0.1975    9.0         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540979d0-8fd6-4847-83b5-729b61ed8ab4",
   "metadata": {},
   "source": [
    "### Rings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "240c2d68-4190-4c4a-8142-89998e3d6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# com_df['Rings_log1p'] = np.log1p(com_df['Rings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef5435-7717-4eae-99cd-76b6d9f3188b",
   "metadata": {},
   "source": [
    "## cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bfaaf-e80c-44ec-bff8-b6b2a7868d05",
   "metadata": {},
   "source": [
    "## 调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b303b7f-b1db-4a55-b6b0-71cf42061620",
   "metadata": {},
   "source": [
    "[bayesHyperTuning.py](bayesHyperTuning.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586b145-220a-4d04-8959-48a61e65623d",
   "metadata": {},
   "source": [
    "## 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d5abc6-7672-4655-8c18-02b21586e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = com_df.loc[train_idx]\n",
    "test_df = com_df.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76f7100-fe21-4f02-ad6c-cc854309a245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94792, 60411)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0], test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecaf7286-8062-4091-afe5-d5e60601b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [c for c in train_df.columns if c not in {'id', 'Rings', 'Rings_log1p', 'Sex'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59b80f45-eb8c-4e13-8926-0f1d1ed93c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Length',\n",
       " 'Diameter',\n",
       " 'Height',\n",
       " 'Whole weight',\n",
       " 'Whole weight.1',\n",
       " 'Whole weight.2',\n",
       " 'Shell weight',\n",
       " 'Sex_code']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aad1a421-4e9f-4fdf-b6fa-f3fa72919264",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Rings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7126d9f-f0ff-44c0-a252-461ae111c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录各次试验的结果\n",
    "oof_df = train_df[['id', 'Rings']].copy()\n",
    "pred_df = test_df[['id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c35d2efa-69bb-4151-a0dd-5f9b945b0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['id'] = pred_df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43977216-c9b6-4e62-8ea0-30dbf24d8be8",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2a9f1-153e-4154-b25f-48e40ae6f22f",
   "metadata": {},
   "source": [
    "#### 默参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25454d1c-c6cb-452b-a464-6a1c388124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_threads': 8,\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'feature_fraction': 1.0,\n",
    "    'reg_alpha': 0.0,\n",
    "    'metric': 'l2',\n",
    "    'early_stopping_rounds': 400,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "417e1cf4-3a33-46fa-aa62-e7183360b04b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.711972\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.47584\n",
      "[200]\tvalid_0's l2: 3.42776\n",
      "[300]\tvalid_0's l2: 3.40394\n",
      "[400]\tvalid_0's l2: 3.39372\n",
      "[500]\tvalid_0's l2: 3.39445\n",
      "[600]\tvalid_0's l2: 3.39006\n",
      "[700]\tvalid_0's l2: 3.39919\n",
      "[800]\tvalid_0's l2: 3.40968\n",
      "[900]\tvalid_0's l2: 3.41138\n",
      "[1000]\tvalid_0's l2: 3.41367\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's l2: 3.39006\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.714425\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.41191\n",
      "[200]\tvalid_0's l2: 3.37033\n",
      "[300]\tvalid_0's l2: 3.37328\n",
      "[400]\tvalid_0's l2: 3.37476\n",
      "[500]\tvalid_0's l2: 3.38424\n",
      "[600]\tvalid_0's l2: 3.39417\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's l2: 3.3662\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.701783\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.47814\n",
      "[200]\tvalid_0's l2: 3.43952\n",
      "[300]\tvalid_0's l2: 3.42397\n",
      "[400]\tvalid_0's l2: 3.42089\n",
      "[500]\tvalid_0's l2: 3.42135\n",
      "[600]\tvalid_0's l2: 3.42711\n",
      "[700]\tvalid_0's l2: 3.43297\n",
      "[800]\tvalid_0's l2: 3.43681\n",
      "Early stopping, best iteration is:\n",
      "[421]\tvalid_0's l2: 3.41903\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1334\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.700636\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.47246\n",
      "[200]\tvalid_0's l2: 3.44445\n",
      "[300]\tvalid_0's l2: 3.43698\n",
      "[400]\tvalid_0's l2: 3.43791\n",
      "[500]\tvalid_0's l2: 3.44125\n",
      "[600]\tvalid_0's l2: 3.44862\n",
      "[700]\tvalid_0's l2: 3.45615\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's l2: 3.43244\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.707348\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's l2: 3.32055\n",
      "[200]\tvalid_0's l2: 3.28901\n",
      "[300]\tvalid_0's l2: 3.28957\n",
      "[400]\tvalid_0's l2: 3.29236\n",
      "[500]\tvalid_0's l2: 3.28969\n",
      "[600]\tvalid_0's l2: 3.30237\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l2: 3.28624\n"
     ]
    }
   ],
   "source": [
    "nfold = 5\n",
    "folds = KFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(train_df.shape[0])\n",
    "pred = np.zeros(test_df.shape[0])\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index)):\n",
    "    print(f'fold={i}', '- ' * 20)\n",
    "    trn_data = lgb.Dataset(train_df.loc[trn_idx, train_cols], label=train_df.loc[trn_idx, target_col], categorical_feature=['Sex_code'])\n",
    "    val_data = lgb.Dataset(train_df.loc[val_idx, train_cols], label=train_df.loc[val_idx, target_col], categorical_feature=['Sex_code'])\n",
    "\n",
    "    model = lgb.train(params, trn_data, 10000, valid_sets=val_data, callbacks=[lgb.log_evaluation(100)])\n",
    "\n",
    "    oof[val_idx] = model.predict(train_df.loc[val_idx, train_cols], num_iteration=model.best_iteration)\n",
    "    pred += model.predict(test_df[train_cols], num_iteration=model.best_iteration) / nfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb60df4e-f98f-44de-ba28-908ccbc7f83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14999862448969184"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error(train_df['Rings'], oof, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66032-b09a-4e37-9e35-2585af94674d",
   "metadata": {},
   "source": [
    "##### 抽象成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c51d4a7e-e3a6-4b5e-8540-f95e6842e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False, nfold=5, num_boost_round=10000):\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        folds = KFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "\n",
    "    target = train_df[target_col]\n",
    "    if log_transform:\n",
    "        target = np.log1p(train_df[target_col])\n",
    "    \n",
    "    oof = np.zeros(train_df.shape[0])\n",
    "    pred = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index, train_df.Rings.astype(int))):\n",
    "    # for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index)):\n",
    "        print(f'fold={i}', '- ' * 20)\n",
    "        trn_data = lgb.Dataset(train_df.loc[trn_idx, train_cols], label=target.loc[trn_idx], categorical_feature=['Sex_code'])\n",
    "        val_data = lgb.Dataset(train_df.loc[val_idx, train_cols], label=target.loc[val_idx], categorical_feature=['Sex_code'])\n",
    "    \n",
    "        model = lgb.train(params, trn_data, num_boost_round, valid_sets=val_data, callbacks=[lgb.log_evaluation(200)])\n",
    "    \n",
    "        oof[val_idx] = model.predict(train_df.loc[val_idx, train_cols], num_iteration=model.best_iteration)\n",
    "        pred += model.predict(test_df[train_cols], num_iteration=model.best_iteration) / nfold\n",
    "\n",
    "    if log_transform:\n",
    "        oof = np.expm1(oof)\n",
    "        pred = np.expm1(pred)\n",
    "\n",
    "    cv = mean_squared_log_error(train_df['Rings'], oof, squared=False)\n",
    "    return cv, oof, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bec0dbc-e07c-4ae9-b7b6-bb18d1497d16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_threads': 8,\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'feature_fraction': 1.0,\n",
    "    'reg_alpha': 0.0,\n",
    "    'metric': 'l2',\n",
    "    'early_stopping_rounds': 400,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50c4ff70-ca2c-4ba9-8d03-81d90c2c7787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.711972\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[200]\tvalid_0's l2: 3.42776\n",
      "[400]\tvalid_0's l2: 3.39372\n",
      "[600]\tvalid_0's l2: 3.39006\n",
      "[800]\tvalid_0's l2: 3.40968\n",
      "[1000]\tvalid_0's l2: 3.41367\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's l2: 3.39006\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.714425\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[200]\tvalid_0's l2: 3.37033\n",
      "[400]\tvalid_0's l2: 3.37476\n",
      "[600]\tvalid_0's l2: 3.39417\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's l2: 3.3662\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.701783\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[200]\tvalid_0's l2: 3.43952\n",
      "[400]\tvalid_0's l2: 3.42089\n",
      "[600]\tvalid_0's l2: 3.42711\n",
      "[800]\tvalid_0's l2: 3.43681\n",
      "Early stopping, best iteration is:\n",
      "[421]\tvalid_0's l2: 3.41903\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1334\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.700636\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[200]\tvalid_0's l2: 3.44445\n",
      "[400]\tvalid_0's l2: 3.43791\n",
      "[600]\tvalid_0's l2: 3.44862\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's l2: 3.43244\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.707348\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[200]\tvalid_0's l2: 3.28901\n",
      "[400]\tvalid_0's l2: 3.29236\n",
      "[600]\tvalid_0's l2: 3.30237\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l2: 3.28624\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = lgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c41494b5-a51f-46e0-9cc5-093028216891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999862448969184\n"
     ]
    }
   ],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'lgb_default'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdaa535-722d-4be3-b8a0-caca8219bdfe",
   "metadata": {},
   "source": [
    "#### BayesianOptimization搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b258a87-f205-4d4a-8e75-053c1233b10a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -0.14929339726508067,\n",
       " 'params': {'bagging_fraction': 0.8309777789028161,\n",
       "  'feature_fraction': 0.8188337656756874,\n",
       "  'learning_rate': 0.011428603279767906,\n",
       "  'max_leaves': 152.77240927641438,\n",
       "  'min_data_in_leaf': 78.74916477965401,\n",
       "  'reg_lambda': 2.1153678521413966}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'target': -0.14929339726508067, 'params': {'bagging_fraction': 0.8309777789028161, 'feature_fraction': 0.8188337656756874, 'learning_rate': 0.011428603279767906, 'max_leaves': 152.77240927641438, 'min_data_in_leaf': 78.74916477965401, 'reg_lambda': 2.1153678521413966}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4294395e-9fe2-41f9-895f-f9381fc4dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_threads': 8,\n",
    "    'objective': 'regression',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 153,\n",
    "    'min_data_in_leaf': 79,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'reg_lambda': 2,\n",
    "    'metric': 'l2',\n",
    "    'early_stopping_rounds': 600,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bd57cbd-2e79-45dc-b84d-eb0fa4a7585a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.711972\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 3.66798\n",
      "[400]\tvalid_0's l2: 3.42491\n",
      "[600]\tvalid_0's l2: 3.38865\n",
      "[800]\tvalid_0's l2: 3.3745\n",
      "[1000]\tvalid_0's l2: 3.36842\n",
      "[1200]\tvalid_0's l2: 3.36546\n",
      "[1400]\tvalid_0's l2: 3.3668\n",
      "[1600]\tvalid_0's l2: 3.36998\n",
      "Early stopping, best iteration is:\n",
      "[1175]\tvalid_0's l2: 3.36522\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.714425\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 3.59392\n",
      "[400]\tvalid_0's l2: 3.36346\n",
      "[600]\tvalid_0's l2: 3.33465\n",
      "[800]\tvalid_0's l2: 3.32518\n",
      "[1000]\tvalid_0's l2: 3.32556\n",
      "[1200]\tvalid_0's l2: 3.32739\n",
      "[1400]\tvalid_0's l2: 3.33093\n",
      "Early stopping, best iteration is:\n",
      "[836]\tvalid_0's l2: 3.32485\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.701783\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 3.67566\n",
      "[400]\tvalid_0's l2: 3.44076\n",
      "[600]\tvalid_0's l2: 3.41029\n",
      "[800]\tvalid_0's l2: 3.40095\n",
      "[1000]\tvalid_0's l2: 3.39826\n",
      "[1200]\tvalid_0's l2: 3.39737\n",
      "[1400]\tvalid_0's l2: 3.39971\n",
      "[1600]\tvalid_0's l2: 3.40423\n",
      "Early stopping, best iteration is:\n",
      "[1068]\tvalid_0's l2: 3.39679\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1334\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.700636\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 3.64652\n",
      "[400]\tvalid_0's l2: 3.43271\n",
      "[600]\tvalid_0's l2: 3.40794\n",
      "[800]\tvalid_0's l2: 3.39852\n",
      "[1000]\tvalid_0's l2: 3.39824\n",
      "[1200]\tvalid_0's l2: 3.39951\n",
      "[1400]\tvalid_0's l2: 3.40175\n",
      "Early stopping, best iteration is:\n",
      "[869]\tvalid_0's l2: 3.39715\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.707348\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 3.49259\n",
      "[400]\tvalid_0's l2: 3.28809\n",
      "[600]\tvalid_0's l2: 3.26442\n",
      "[800]\tvalid_0's l2: 3.25961\n",
      "[1000]\tvalid_0's l2: 3.25886\n",
      "[1200]\tvalid_0's l2: 3.26318\n",
      "[1400]\tvalid_0's l2: 3.26869\n",
      "Early stopping, best iteration is:\n",
      "[948]\tvalid_0's l2: 3.2583\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = lgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3685e25b-2984-4ffd-a9dc-9521cbe5eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14942425821831296"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b377e264-519a-4489-adcc-6a2aeb8cc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'lgb_bo'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f6453-cf78-4fd3-8b57-63be1609319b",
   "metadata": {},
   "source": [
    "#### Rings_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55f22f70-9628-4d6f-8dda-3a260813aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_threads': 8,\n",
    "    'objective': 'regression',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 153,\n",
    "    'min_data_in_leaf': 79,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'reg_lambda': 2,\n",
    "    'metric': 'l2',\n",
    "    'early_stopping_rounds': 600,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99ad7d3f-4706-4684-babe-1d59e803e689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.330406\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0243383\n",
      "[400]\tvalid_0's l2: 0.0226028\n",
      "[600]\tvalid_0's l2: 0.0223965\n",
      "[800]\tvalid_0's l2: 0.0223149\n",
      "[1000]\tvalid_0's l2: 0.0222736\n",
      "[1200]\tvalid_0's l2: 0.0222614\n",
      "[1400]\tvalid_0's l2: 0.022265\n",
      "[1600]\tvalid_0's l2: 0.0222842\n",
      "[1800]\tvalid_0's l2: 0.0223089\n",
      "Early stopping, best iteration is:\n",
      "[1201]\tvalid_0's l2: 0.0222612\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.330672\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0242979\n",
      "[400]\tvalid_0's l2: 0.0225232\n",
      "[600]\tvalid_0's l2: 0.0223333\n",
      "[800]\tvalid_0's l2: 0.0222775\n",
      "[1000]\tvalid_0's l2: 0.0222537\n",
      "[1200]\tvalid_0's l2: 0.0222494\n",
      "[1400]\tvalid_0's l2: 0.0222617\n",
      "[1600]\tvalid_0's l2: 0.022279\n",
      "Early stopping, best iteration is:\n",
      "[1103]\tvalid_0's l2: 0.022244\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329520\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.024152\n",
      "[400]\tvalid_0's l2: 0.022428\n",
      "[600]\tvalid_0's l2: 0.0222433\n",
      "[800]\tvalid_0's l2: 0.0221711\n",
      "[1000]\tvalid_0's l2: 0.0221351\n",
      "[1200]\tvalid_0's l2: 0.0221226\n",
      "[1400]\tvalid_0's l2: 0.0221346\n",
      "[1600]\tvalid_0's l2: 0.0221484\n",
      "Early stopping, best iteration is:\n",
      "[1199]\tvalid_0's l2: 0.0221226\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1334\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329248\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0242186\n",
      "[400]\tvalid_0's l2: 0.0226379\n",
      "[600]\tvalid_0's l2: 0.0224842\n",
      "[800]\tvalid_0's l2: 0.0224496\n",
      "[1000]\tvalid_0's l2: 0.0224378\n",
      "[1200]\tvalid_0's l2: 0.0224446\n",
      "[1400]\tvalid_0's l2: 0.0224619\n",
      "[1600]\tvalid_0's l2: 0.0224925\n",
      "Early stopping, best iteration is:\n",
      "[1015]\tvalid_0's l2: 0.0224369\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329782\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0232458\n",
      "[400]\tvalid_0's l2: 0.0217028\n",
      "[600]\tvalid_0's l2: 0.0215653\n",
      "[800]\tvalid_0's l2: 0.021538\n",
      "[1000]\tvalid_0's l2: 0.0215262\n",
      "[1200]\tvalid_0's l2: 0.0215382\n",
      "[1400]\tvalid_0's l2: 0.0215589\n",
      "Early stopping, best iteration is:\n",
      "[993]\tvalid_0's l2: 0.0215241\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = lgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=True, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a955037d-e002-467c-9fd9-287ebf7671e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14872039902852816"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7efea1a-54ea-4766-bfe8-4df46b303e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = 'lgb_bo_log1p'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63aee6-1408-45ba-88d1-7bed8d85688e",
   "metadata": {},
   "source": [
    "#### StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a820a41-62d4-4ce2-8ec8-878085c49129",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_threads': 8,\n",
    "    'objective': 'regression',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 153,\n",
    "    'min_data_in_leaf': 79,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'reg_lambda': 2,\n",
    "    'metric': 'l2',\n",
    "    'early_stopping_rounds': 600,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "654c7b16-cea3-48e4-b51b-afa0da09732c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329900\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0239959\n",
      "[400]\tvalid_0's l2: 0.0224168\n",
      "[600]\tvalid_0's l2: 0.0222771\n",
      "[800]\tvalid_0's l2: 0.0222325\n",
      "[1000]\tvalid_0's l2: 0.022217\n",
      "[1200]\tvalid_0's l2: 0.0222331\n",
      "[1400]\tvalid_0's l2: 0.0222477\n",
      "[1600]\tvalid_0's l2: 0.0222799\n",
      "Early stopping, best iteration is:\n",
      "[1024]\tvalid_0's l2: 0.0222151\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1330\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329901\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0235794\n",
      "[400]\tvalid_0's l2: 0.0219787\n",
      "[600]\tvalid_0's l2: 0.0218227\n",
      "[800]\tvalid_0's l2: 0.0217766\n",
      "[1000]\tvalid_0's l2: 0.0217562\n",
      "[1200]\tvalid_0's l2: 0.0217442\n",
      "[1400]\tvalid_0's l2: 0.0217458\n",
      "[1600]\tvalid_0's l2: 0.0217708\n",
      "Early stopping, best iteration is:\n",
      "[1188]\tvalid_0's l2: 0.0217438\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329912\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0241635\n",
      "[400]\tvalid_0's l2: 0.0223344\n",
      "[600]\tvalid_0's l2: 0.0221326\n",
      "[800]\tvalid_0's l2: 0.0220759\n",
      "[1000]\tvalid_0's l2: 0.0220571\n",
      "[1200]\tvalid_0's l2: 0.0220567\n",
      "[1400]\tvalid_0's l2: 0.0220788\n",
      "[1600]\tvalid_0's l2: 0.0221095\n",
      "Early stopping, best iteration is:\n",
      "[1070]\tvalid_0's l2: 0.0220539\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1331\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329960\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0244072\n",
      "[400]\tvalid_0's l2: 0.0226779\n",
      "[600]\tvalid_0's l2: 0.0224763\n",
      "[800]\tvalid_0's l2: 0.0224106\n",
      "[1000]\tvalid_0's l2: 0.0223794\n",
      "[1200]\tvalid_0's l2: 0.0223719\n",
      "[1400]\tvalid_0's l2: 0.0223789\n",
      "[1600]\tvalid_0's l2: 0.0223942\n",
      "Early stopping, best iteration is:\n",
      "[1124]\tvalid_0's l2: 0.0223683\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1333\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 2.329954\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[200]\tvalid_0's l2: 0.0240261\n",
      "[400]\tvalid_0's l2: 0.0223466\n",
      "[600]\tvalid_0's l2: 0.0221744\n",
      "[800]\tvalid_0's l2: 0.0221218\n",
      "[1000]\tvalid_0's l2: 0.0220923\n",
      "[1200]\tvalid_0's l2: 0.0220906\n",
      "[1400]\tvalid_0's l2: 0.0220964\n",
      "[1600]\tvalid_0's l2: 0.0221095\n",
      "Early stopping, best iteration is:\n",
      "[1093]\tvalid_0's l2: 0.0220833\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = lgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=True, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34612e24-1752-4fee-b0eb-ca3bba49fcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1486366782823439\n"
     ]
    }
   ],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'lgb_bo_log1p_skf'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceaa3e1-7c7d-45d2-abc2-d0aaaa1ae385",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2250203f-f0a8-420c-9d46-eba727195ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False, nfold=5, num_boost_round=10000):\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        folds = KFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "\n",
    "    target = train_df[target_col]\n",
    "    if log_transform:\n",
    "        target = np.log1p(train_df[target_col])\n",
    "    \n",
    "    oof = np.zeros(train_df.shape[0])\n",
    "    pred = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index, train_df.Rings.astype(int))):\n",
    "        print(f'fold={i}', '- ' * 20)\n",
    "        trn_data = xgb.DMatrix(train_df.loc[trn_idx, train_cols], label=target.loc[trn_idx])\n",
    "        val_data = xgb.DMatrix(train_df.loc[val_idx, train_cols], label=target.loc[val_idx])\n",
    "        tst_data = xgb.DMatrix(test_df[train_cols])\n",
    "        \n",
    "        model = xgb.train(params, trn_data, num_boost_round, evals=[(val_data, 'dev')], early_stopping_rounds=400, verbose_eval=200)\n",
    "\n",
    "        oof[val_idx] = model.predict(val_data, iteration_range=(0, model.best_iteration + 1))\n",
    "        pred += model.predict(tst_data, iteration_range=(0, model.best_iteration + 1)) / nfold\n",
    "\n",
    "    if log_transform:\n",
    "        oof = np.expm1(oof)\n",
    "        pred = np.expm1(pred)\n",
    "\n",
    "    cv = mean_squared_log_error(train_df['Rings'], oof, squared=False)\n",
    "    return cv, oof, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d77bd-0ec8-4b66-9bac-31fd35b2d44a",
   "metadata": {},
   "source": [
    "#### 默参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e62ab505-4f6b-4c0c-bccb-83979351ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nthread': 8,\n",
    "    'objective': 'reg:squarederror',    # reg:squaredlogerror\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.3,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'alpha': 1,\n",
    "    'eval_metric': 'rmse',    # rmsle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0debe2e-9af3-4581-b2f5-2bcc16c2cb8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:2.65168\n",
      "[200]\tdev-rmse:1.87031\n",
      "[400]\tdev-rmse:1.88657\n",
      "[492]\tdev-rmse:1.89677\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:2.63033\n",
      "[200]\tdev-rmse:1.87420\n",
      "[400]\tdev-rmse:1.90440\n",
      "[471]\tdev-rmse:1.91330\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:2.66109\n",
      "[200]\tdev-rmse:1.88798\n",
      "[400]\tdev-rmse:1.90691\n",
      "[456]\tdev-rmse:1.91279\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:2.63675\n",
      "[200]\tdev-rmse:1.88913\n",
      "[400]\tdev-rmse:1.91897\n",
      "[475]\tdev-rmse:1.92663\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:2.60731\n",
      "[200]\tdev-rmse:1.85507\n",
      "[400]\tdev-rmse:1.89547\n",
      "[454]\tdev-rmse:1.90564\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = xgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7a107f5-4a73-48ec-9b45-a8ba79ec1f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15131418837566096\n"
     ]
    }
   ],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'xgb_default'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196187d-a6a4-4429-91e6-61a4642d8d13",
   "metadata": {},
   "source": [
    "#### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "577ab9fb-8c0f-44c1-859c-240cfa0e4d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -0.14958736584324933,\n",
       " 'params': {'colsample_bytree': 0.7866142255075863,\n",
       "  'learning_rate': 0.014675616499216792,\n",
       "  'max_depth': 4.306206369690987,\n",
       "  'min_child_weight': 22.35153866873263,\n",
       "  'reg_lambda': 8.041098074819361,\n",
       "  'subsample': 0.8960766330914962}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'target': -0.14958736584324933, 'params': {'colsample_bytree': 0.7866142255075863, 'learning_rate': 0.014675616499216792, 'max_depth': 4.306206369690987, 'min_child_weight': 22.35153866873263, 'reg_lambda': 8.041098074819361, 'subsample': 0.8960766330914962}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9873e0da-1600-4d9b-9478-dda8f70d2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nthread': 8,\n",
    "    'objective': 'reg:squarederror',    # reg:squaredlogerror\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.015,\n",
    "    'min_child_weight': 22.4,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_lambda': 8.0,\n",
    "    'eval_metric': 'rmse',    # rmsle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a3e21b0-ac3c-4450-91a3-f06b3039f9ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.16669\n",
      "[200]\tdev-rmse:1.95863\n",
      "[400]\tdev-rmse:1.90680\n",
      "[600]\tdev-rmse:1.88992\n",
      "[800]\tdev-rmse:1.88089\n",
      "[1000]\tdev-rmse:1.87340\n",
      "[1200]\tdev-rmse:1.86792\n",
      "[1400]\tdev-rmse:1.86354\n",
      "[1600]\tdev-rmse:1.86037\n",
      "[1800]\tdev-rmse:1.85731\n",
      "[2000]\tdev-rmse:1.85492\n",
      "[2200]\tdev-rmse:1.85306\n",
      "[2400]\tdev-rmse:1.85113\n",
      "[2600]\tdev-rmse:1.84960\n",
      "[2800]\tdev-rmse:1.84824\n",
      "[3000]\tdev-rmse:1.84694\n",
      "[3200]\tdev-rmse:1.84568\n",
      "[3400]\tdev-rmse:1.84489\n",
      "[3600]\tdev-rmse:1.84408\n",
      "[3800]\tdev-rmse:1.84317\n",
      "[4000]\tdev-rmse:1.84247\n",
      "[4200]\tdev-rmse:1.84189\n",
      "[4400]\tdev-rmse:1.84122\n",
      "[4600]\tdev-rmse:1.84079\n",
      "[4800]\tdev-rmse:1.84028\n",
      "[5000]\tdev-rmse:1.83966\n",
      "[5200]\tdev-rmse:1.83932\n",
      "[5400]\tdev-rmse:1.83891\n",
      "[5600]\tdev-rmse:1.83838\n",
      "[5800]\tdev-rmse:1.83809\n",
      "[6000]\tdev-rmse:1.83772\n",
      "[6200]\tdev-rmse:1.83753\n",
      "[6400]\tdev-rmse:1.83723\n",
      "[6600]\tdev-rmse:1.83709\n",
      "[6800]\tdev-rmse:1.83690\n",
      "[7000]\tdev-rmse:1.83672\n",
      "[7200]\tdev-rmse:1.83657\n",
      "[7400]\tdev-rmse:1.83650\n",
      "[7600]\tdev-rmse:1.83642\n",
      "[7800]\tdev-rmse:1.83628\n",
      "[8000]\tdev-rmse:1.83620\n",
      "[8200]\tdev-rmse:1.83608\n",
      "[8400]\tdev-rmse:1.83583\n",
      "[8600]\tdev-rmse:1.83579\n",
      "[8800]\tdev-rmse:1.83578\n",
      "[9000]\tdev-rmse:1.83584\n",
      "[9104]\tdev-rmse:1.83578\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.14898\n",
      "[200]\tdev-rmse:1.93044\n",
      "[400]\tdev-rmse:1.88231\n",
      "[600]\tdev-rmse:1.86807\n",
      "[800]\tdev-rmse:1.86056\n",
      "[1000]\tdev-rmse:1.85536\n",
      "[1200]\tdev-rmse:1.85106\n",
      "[1400]\tdev-rmse:1.84772\n",
      "[1600]\tdev-rmse:1.84534\n",
      "[1800]\tdev-rmse:1.84308\n",
      "[2000]\tdev-rmse:1.84129\n",
      "[2200]\tdev-rmse:1.84015\n",
      "[2400]\tdev-rmse:1.83903\n",
      "[2600]\tdev-rmse:1.83776\n",
      "[2800]\tdev-rmse:1.83736\n",
      "[3000]\tdev-rmse:1.83665\n",
      "[3200]\tdev-rmse:1.83600\n",
      "[3400]\tdev-rmse:1.83564\n",
      "[3600]\tdev-rmse:1.83518\n",
      "[3800]\tdev-rmse:1.83476\n",
      "[4000]\tdev-rmse:1.83453\n",
      "[4200]\tdev-rmse:1.83418\n",
      "[4400]\tdev-rmse:1.83413\n",
      "[4600]\tdev-rmse:1.83404\n",
      "[4800]\tdev-rmse:1.83389\n",
      "[5000]\tdev-rmse:1.83375\n",
      "[5200]\tdev-rmse:1.83363\n",
      "[5400]\tdev-rmse:1.83366\n",
      "[5600]\tdev-rmse:1.83362\n",
      "[5800]\tdev-rmse:1.83336\n",
      "[6000]\tdev-rmse:1.83323\n",
      "[6200]\tdev-rmse:1.83312\n",
      "[6400]\tdev-rmse:1.83322\n",
      "[6515]\tdev-rmse:1.83323\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.18180\n",
      "[200]\tdev-rmse:1.95697\n",
      "[400]\tdev-rmse:1.90619\n",
      "[600]\tdev-rmse:1.88990\n",
      "[800]\tdev-rmse:1.88163\n",
      "[1000]\tdev-rmse:1.87514\n",
      "[1200]\tdev-rmse:1.87081\n",
      "[1400]\tdev-rmse:1.86698\n",
      "[1600]\tdev-rmse:1.86412\n",
      "[1800]\tdev-rmse:1.86158\n",
      "[2000]\tdev-rmse:1.85953\n",
      "[2200]\tdev-rmse:1.85835\n",
      "[2400]\tdev-rmse:1.85692\n",
      "[2600]\tdev-rmse:1.85602\n",
      "[2800]\tdev-rmse:1.85522\n",
      "[3000]\tdev-rmse:1.85441\n",
      "[3200]\tdev-rmse:1.85382\n",
      "[3400]\tdev-rmse:1.85290\n",
      "[3600]\tdev-rmse:1.85231\n",
      "[3800]\tdev-rmse:1.85188\n",
      "[4000]\tdev-rmse:1.85150\n",
      "[4200]\tdev-rmse:1.85120\n",
      "[4400]\tdev-rmse:1.85095\n",
      "[4600]\tdev-rmse:1.85086\n",
      "[4800]\tdev-rmse:1.85045\n",
      "[5000]\tdev-rmse:1.85027\n",
      "[5200]\tdev-rmse:1.84993\n",
      "[5400]\tdev-rmse:1.84991\n",
      "[5600]\tdev-rmse:1.84967\n",
      "[5800]\tdev-rmse:1.84948\n",
      "[6000]\tdev-rmse:1.84935\n",
      "[6200]\tdev-rmse:1.84915\n",
      "[6400]\tdev-rmse:1.84912\n",
      "[6600]\tdev-rmse:1.84903\n",
      "[6800]\tdev-rmse:1.84901\n",
      "[7000]\tdev-rmse:1.84914\n",
      "[7099]\tdev-rmse:1.84914\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.15374\n",
      "[200]\tdev-rmse:1.94649\n",
      "[400]\tdev-rmse:1.89741\n",
      "[600]\tdev-rmse:1.88345\n",
      "[800]\tdev-rmse:1.87550\n",
      "[1000]\tdev-rmse:1.86969\n",
      "[1200]\tdev-rmse:1.86574\n",
      "[1400]\tdev-rmse:1.86254\n",
      "[1600]\tdev-rmse:1.85983\n",
      "[1800]\tdev-rmse:1.85769\n",
      "[2000]\tdev-rmse:1.85568\n",
      "[2200]\tdev-rmse:1.85462\n",
      "[2400]\tdev-rmse:1.85348\n",
      "[2600]\tdev-rmse:1.85233\n",
      "[2800]\tdev-rmse:1.85133\n",
      "[3000]\tdev-rmse:1.85054\n",
      "[3200]\tdev-rmse:1.84970\n",
      "[3400]\tdev-rmse:1.84911\n",
      "[3600]\tdev-rmse:1.84876\n",
      "[3800]\tdev-rmse:1.84815\n",
      "[4000]\tdev-rmse:1.84799\n",
      "[4200]\tdev-rmse:1.84758\n",
      "[4400]\tdev-rmse:1.84730\n",
      "[4600]\tdev-rmse:1.84693\n",
      "[4800]\tdev-rmse:1.84690\n",
      "[5000]\tdev-rmse:1.84663\n",
      "[5200]\tdev-rmse:1.84639\n",
      "[5400]\tdev-rmse:1.84610\n",
      "[5600]\tdev-rmse:1.84601\n",
      "[5800]\tdev-rmse:1.84614\n",
      "[6000]\tdev-rmse:1.84598\n",
      "[6200]\tdev-rmse:1.84579\n",
      "[6400]\tdev-rmse:1.84568\n",
      "[6600]\tdev-rmse:1.84573\n",
      "[6725]\tdev-rmse:1.84588\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.12850\n",
      "[200]\tdev-rmse:1.90630\n",
      "[400]\tdev-rmse:1.85815\n",
      "[600]\tdev-rmse:1.84447\n",
      "[800]\tdev-rmse:1.83646\n",
      "[1000]\tdev-rmse:1.83145\n",
      "[1200]\tdev-rmse:1.82801\n",
      "[1400]\tdev-rmse:1.82499\n",
      "[1600]\tdev-rmse:1.82299\n",
      "[1800]\tdev-rmse:1.82121\n",
      "[2000]\tdev-rmse:1.81979\n",
      "[2200]\tdev-rmse:1.81844\n",
      "[2400]\tdev-rmse:1.81749\n",
      "[2600]\tdev-rmse:1.81685\n",
      "[2800]\tdev-rmse:1.81641\n",
      "[3000]\tdev-rmse:1.81582\n",
      "[3200]\tdev-rmse:1.81519\n",
      "[3400]\tdev-rmse:1.81476\n",
      "[3600]\tdev-rmse:1.81431\n",
      "[3800]\tdev-rmse:1.81407\n",
      "[4000]\tdev-rmse:1.81381\n",
      "[4200]\tdev-rmse:1.81358\n",
      "[4400]\tdev-rmse:1.81345\n",
      "[4600]\tdev-rmse:1.81320\n",
      "[4800]\tdev-rmse:1.81324\n",
      "[5000]\tdev-rmse:1.81324\n",
      "[5155]\tdev-rmse:1.81341\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = xgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e18071de-cefc-4f18-83d6-72e3c420d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14985199712298292\n"
     ]
    }
   ],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'xgb_bo'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c896b-4394-415e-8703-cc5fd3384502",
   "metadata": {},
   "source": [
    "#### Rings_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d272062c-648a-4d77-b691-544fcad21ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nthread': 8,\n",
    "    'objective': 'reg:squarederror',    # reg:squaredlogerror\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.015,\n",
    "    'min_child_weight': 22.4,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_lambda': 8.0,\n",
    "    'eval_metric': 'rmse',    # rmsle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7f447a9-4e84-4ac3-9ae2-e9ffef2412f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28331\n",
      "[200]\tdev-rmse:0.15859\n",
      "[400]\tdev-rmse:0.15433\n",
      "[600]\tdev-rmse:0.15310\n",
      "[800]\tdev-rmse:0.15247\n",
      "[1000]\tdev-rmse:0.15201\n",
      "[1200]\tdev-rmse:0.15166\n",
      "[1400]\tdev-rmse:0.15140\n",
      "[1600]\tdev-rmse:0.15121\n",
      "[1800]\tdev-rmse:0.15103\n",
      "[2000]\tdev-rmse:0.15089\n",
      "[2200]\tdev-rmse:0.15075\n",
      "[2400]\tdev-rmse:0.15061\n",
      "[2600]\tdev-rmse:0.15051\n",
      "[2800]\tdev-rmse:0.15041\n",
      "[3000]\tdev-rmse:0.15031\n",
      "[3200]\tdev-rmse:0.15024\n",
      "[3400]\tdev-rmse:0.15017\n",
      "[3600]\tdev-rmse:0.15012\n",
      "[3800]\tdev-rmse:0.15007\n",
      "[4000]\tdev-rmse:0.15003\n",
      "[4200]\tdev-rmse:0.14998\n",
      "[4400]\tdev-rmse:0.14994\n",
      "[4600]\tdev-rmse:0.14990\n",
      "[4800]\tdev-rmse:0.14987\n",
      "[5000]\tdev-rmse:0.14984\n",
      "[5200]\tdev-rmse:0.14981\n",
      "[5400]\tdev-rmse:0.14979\n",
      "[5600]\tdev-rmse:0.14975\n",
      "[5800]\tdev-rmse:0.14973\n",
      "[6000]\tdev-rmse:0.14971\n",
      "[6200]\tdev-rmse:0.14969\n",
      "[6400]\tdev-rmse:0.14967\n",
      "[6600]\tdev-rmse:0.14965\n",
      "[6800]\tdev-rmse:0.14962\n",
      "[7000]\tdev-rmse:0.14962\n",
      "[7200]\tdev-rmse:0.14961\n",
      "[7400]\tdev-rmse:0.14960\n",
      "[7600]\tdev-rmse:0.14959\n",
      "[7800]\tdev-rmse:0.14958\n",
      "[8000]\tdev-rmse:0.14957\n",
      "[8200]\tdev-rmse:0.14957\n",
      "[8400]\tdev-rmse:0.14956\n",
      "[8600]\tdev-rmse:0.14955\n",
      "[8800]\tdev-rmse:0.14955\n",
      "[9000]\tdev-rmse:0.14955\n",
      "[9200]\tdev-rmse:0.14955\n",
      "[9400]\tdev-rmse:0.14955\n",
      "[9489]\tdev-rmse:0.14955\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28467\n",
      "[200]\tdev-rmse:0.15773\n",
      "[400]\tdev-rmse:0.15353\n",
      "[600]\tdev-rmse:0.15239\n",
      "[800]\tdev-rmse:0.15183\n",
      "[1000]\tdev-rmse:0.15146\n",
      "[1200]\tdev-rmse:0.15117\n",
      "[1400]\tdev-rmse:0.15095\n",
      "[1600]\tdev-rmse:0.15079\n",
      "[1800]\tdev-rmse:0.15063\n",
      "[2000]\tdev-rmse:0.15049\n",
      "[2200]\tdev-rmse:0.15040\n",
      "[2400]\tdev-rmse:0.15031\n",
      "[2600]\tdev-rmse:0.15024\n",
      "[2800]\tdev-rmse:0.15019\n",
      "[3000]\tdev-rmse:0.15014\n",
      "[3200]\tdev-rmse:0.15008\n",
      "[3400]\tdev-rmse:0.15004\n",
      "[3600]\tdev-rmse:0.15001\n",
      "[3800]\tdev-rmse:0.14997\n",
      "[4000]\tdev-rmse:0.14995\n",
      "[4200]\tdev-rmse:0.14991\n",
      "[4400]\tdev-rmse:0.14990\n",
      "[4600]\tdev-rmse:0.14988\n",
      "[4800]\tdev-rmse:0.14987\n",
      "[5000]\tdev-rmse:0.14985\n",
      "[5200]\tdev-rmse:0.14985\n",
      "[5400]\tdev-rmse:0.14984\n",
      "[5600]\tdev-rmse:0.14983\n",
      "[5800]\tdev-rmse:0.14981\n",
      "[6000]\tdev-rmse:0.14981\n",
      "[6200]\tdev-rmse:0.14981\n",
      "[6400]\tdev-rmse:0.14980\n",
      "[6600]\tdev-rmse:0.14980\n",
      "[6800]\tdev-rmse:0.14980\n",
      "[6906]\tdev-rmse:0.14979\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28432\n",
      "[200]\tdev-rmse:0.15798\n",
      "[400]\tdev-rmse:0.15376\n",
      "[600]\tdev-rmse:0.15247\n",
      "[800]\tdev-rmse:0.15186\n",
      "[1000]\tdev-rmse:0.15140\n",
      "[1200]\tdev-rmse:0.15105\n",
      "[1400]\tdev-rmse:0.15078\n",
      "[1600]\tdev-rmse:0.15057\n",
      "[1800]\tdev-rmse:0.15041\n",
      "[2000]\tdev-rmse:0.15025\n",
      "[2200]\tdev-rmse:0.15015\n",
      "[2400]\tdev-rmse:0.15004\n",
      "[2600]\tdev-rmse:0.14997\n",
      "[2800]\tdev-rmse:0.14990\n",
      "[3000]\tdev-rmse:0.14984\n",
      "[3200]\tdev-rmse:0.14979\n",
      "[3400]\tdev-rmse:0.14973\n",
      "[3600]\tdev-rmse:0.14968\n",
      "[3800]\tdev-rmse:0.14964\n",
      "[4000]\tdev-rmse:0.14960\n",
      "[4200]\tdev-rmse:0.14957\n",
      "[4400]\tdev-rmse:0.14954\n",
      "[4600]\tdev-rmse:0.14951\n",
      "[4800]\tdev-rmse:0.14947\n",
      "[5000]\tdev-rmse:0.14946\n",
      "[5200]\tdev-rmse:0.14943\n",
      "[5400]\tdev-rmse:0.14941\n",
      "[5600]\tdev-rmse:0.14939\n",
      "[5800]\tdev-rmse:0.14936\n",
      "[6000]\tdev-rmse:0.14936\n",
      "[6200]\tdev-rmse:0.14935\n",
      "[6400]\tdev-rmse:0.14932\n",
      "[6600]\tdev-rmse:0.14932\n",
      "[6800]\tdev-rmse:0.14931\n",
      "[7000]\tdev-rmse:0.14930\n",
      "[7200]\tdev-rmse:0.14930\n",
      "[7400]\tdev-rmse:0.14928\n",
      "[7600]\tdev-rmse:0.14928\n",
      "[7800]\tdev-rmse:0.14926\n",
      "[8000]\tdev-rmse:0.14925\n",
      "[8200]\tdev-rmse:0.14926\n",
      "[8351]\tdev-rmse:0.14925\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28228\n",
      "[200]\tdev-rmse:0.15788\n",
      "[400]\tdev-rmse:0.15379\n",
      "[600]\tdev-rmse:0.15268\n",
      "[800]\tdev-rmse:0.15212\n",
      "[1000]\tdev-rmse:0.15175\n",
      "[1200]\tdev-rmse:0.15147\n",
      "[1400]\tdev-rmse:0.15123\n",
      "[1600]\tdev-rmse:0.15108\n",
      "[1800]\tdev-rmse:0.15095\n",
      "[2000]\tdev-rmse:0.15083\n",
      "[2200]\tdev-rmse:0.15073\n",
      "[2400]\tdev-rmse:0.15065\n",
      "[2600]\tdev-rmse:0.15057\n",
      "[2800]\tdev-rmse:0.15051\n",
      "[3000]\tdev-rmse:0.15046\n",
      "[3200]\tdev-rmse:0.15041\n",
      "[3400]\tdev-rmse:0.15036\n",
      "[3600]\tdev-rmse:0.15033\n",
      "[3800]\tdev-rmse:0.15031\n",
      "[4000]\tdev-rmse:0.15030\n",
      "[4200]\tdev-rmse:0.15028\n",
      "[4400]\tdev-rmse:0.15025\n",
      "[4600]\tdev-rmse:0.15023\n",
      "[4800]\tdev-rmse:0.15023\n",
      "[5000]\tdev-rmse:0.15021\n",
      "[5200]\tdev-rmse:0.15020\n",
      "[5400]\tdev-rmse:0.15019\n",
      "[5600]\tdev-rmse:0.15018\n",
      "[5800]\tdev-rmse:0.15017\n",
      "[6000]\tdev-rmse:0.15016\n",
      "[6200]\tdev-rmse:0.15017\n",
      "[6400]\tdev-rmse:0.15017\n",
      "[6422]\tdev-rmse:0.15017\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28100\n",
      "[200]\tdev-rmse:0.15487\n",
      "[400]\tdev-rmse:0.15073\n",
      "[600]\tdev-rmse:0.14958\n",
      "[800]\tdev-rmse:0.14897\n",
      "[1000]\tdev-rmse:0.14857\n",
      "[1200]\tdev-rmse:0.14828\n",
      "[1400]\tdev-rmse:0.14806\n",
      "[1600]\tdev-rmse:0.14790\n",
      "[1800]\tdev-rmse:0.14778\n",
      "[2000]\tdev-rmse:0.14767\n",
      "[2200]\tdev-rmse:0.14758\n",
      "[2400]\tdev-rmse:0.14750\n",
      "[2600]\tdev-rmse:0.14745\n",
      "[2800]\tdev-rmse:0.14741\n",
      "[3000]\tdev-rmse:0.14737\n",
      "[3200]\tdev-rmse:0.14734\n",
      "[3400]\tdev-rmse:0.14730\n",
      "[3600]\tdev-rmse:0.14728\n",
      "[3800]\tdev-rmse:0.14726\n",
      "[4000]\tdev-rmse:0.14724\n",
      "[4200]\tdev-rmse:0.14723\n",
      "[4400]\tdev-rmse:0.14723\n",
      "[4579]\tdev-rmse:0.14723\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = xgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=True, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "683b2b50-c838-4149-acf6-7947d3c107b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1491971661825225\n"
     ]
    }
   ],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'xgb_bo_log1p'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f2f1644-c1f6-40da-8b56-674d6e9ad381",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7a01054-ec23-418e-b46d-1a31a57064d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=nfold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78f431b0-b01f-4946-ae2e-c03f1c90bbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.16669\n",
      "[100]\tdev-rmse:2.11483\n",
      "[200]\tdev-rmse:1.95863\n",
      "[300]\tdev-rmse:1.92244\n",
      "[400]\tdev-rmse:1.90680\n",
      "[500]\tdev-rmse:1.89703\n",
      "[600]\tdev-rmse:1.88992\n",
      "[700]\tdev-rmse:1.88462\n",
      "[800]\tdev-rmse:1.88089\n",
      "[900]\tdev-rmse:1.87663\n",
      "[1000]\tdev-rmse:1.87340\n",
      "[1100]\tdev-rmse:1.87062\n",
      "[1200]\tdev-rmse:1.86792\n",
      "[1300]\tdev-rmse:1.86575\n",
      "[1400]\tdev-rmse:1.86354\n",
      "[1500]\tdev-rmse:1.86187\n",
      "[1600]\tdev-rmse:1.86037\n",
      "[1700]\tdev-rmse:1.85883\n",
      "[1800]\tdev-rmse:1.85731\n",
      "[1900]\tdev-rmse:1.85590\n",
      "[2000]\tdev-rmse:1.85492\n",
      "[2100]\tdev-rmse:1.85375\n",
      "[2200]\tdev-rmse:1.85306\n",
      "[2300]\tdev-rmse:1.85202\n",
      "[2400]\tdev-rmse:1.85113\n",
      "[2500]\tdev-rmse:1.85053\n",
      "[2600]\tdev-rmse:1.84960\n",
      "[2700]\tdev-rmse:1.84891\n",
      "[2800]\tdev-rmse:1.84824\n",
      "[2900]\tdev-rmse:1.84778\n",
      "[3000]\tdev-rmse:1.84694\n",
      "[3100]\tdev-rmse:1.84623\n",
      "[3200]\tdev-rmse:1.84568\n",
      "[3300]\tdev-rmse:1.84519\n",
      "[3400]\tdev-rmse:1.84489\n",
      "[3500]\tdev-rmse:1.84445\n",
      "[3600]\tdev-rmse:1.84408\n",
      "[3700]\tdev-rmse:1.84369\n",
      "[3800]\tdev-rmse:1.84317\n",
      "[3900]\tdev-rmse:1.84278\n",
      "[4000]\tdev-rmse:1.84247\n",
      "[4100]\tdev-rmse:1.84219\n",
      "[4200]\tdev-rmse:1.84189\n",
      "[4300]\tdev-rmse:1.84152\n",
      "[4400]\tdev-rmse:1.84122\n",
      "[4500]\tdev-rmse:1.84106\n",
      "[4600]\tdev-rmse:1.84079\n",
      "[4700]\tdev-rmse:1.84056\n",
      "[4800]\tdev-rmse:1.84028\n",
      "[4900]\tdev-rmse:1.83991\n",
      "[5000]\tdev-rmse:1.83966\n",
      "[5100]\tdev-rmse:1.83948\n",
      "[5200]\tdev-rmse:1.83932\n",
      "[5300]\tdev-rmse:1.83910\n",
      "[5400]\tdev-rmse:1.83891\n",
      "[5500]\tdev-rmse:1.83863\n",
      "[5600]\tdev-rmse:1.83838\n",
      "[5700]\tdev-rmse:1.83828\n",
      "[5800]\tdev-rmse:1.83809\n",
      "[5900]\tdev-rmse:1.83784\n",
      "[6000]\tdev-rmse:1.83772\n",
      "[6100]\tdev-rmse:1.83755\n",
      "[6200]\tdev-rmse:1.83753\n",
      "[6300]\tdev-rmse:1.83739\n",
      "[6400]\tdev-rmse:1.83723\n",
      "[6500]\tdev-rmse:1.83716\n",
      "[6600]\tdev-rmse:1.83709\n",
      "[6700]\tdev-rmse:1.83700\n",
      "[6800]\tdev-rmse:1.83690\n",
      "[6900]\tdev-rmse:1.83682\n",
      "[7000]\tdev-rmse:1.83672\n",
      "[7100]\tdev-rmse:1.83668\n",
      "[7200]\tdev-rmse:1.83657\n",
      "[7300]\tdev-rmse:1.83652\n",
      "[7400]\tdev-rmse:1.83650\n",
      "[7500]\tdev-rmse:1.83641\n",
      "[7600]\tdev-rmse:1.83642\n",
      "[7700]\tdev-rmse:1.83635\n",
      "[7800]\tdev-rmse:1.83628\n",
      "[7900]\tdev-rmse:1.83623\n",
      "[8000]\tdev-rmse:1.83620\n",
      "[8100]\tdev-rmse:1.83613\n",
      "[8200]\tdev-rmse:1.83608\n",
      "[8300]\tdev-rmse:1.83597\n",
      "[8400]\tdev-rmse:1.83583\n",
      "[8500]\tdev-rmse:1.83587\n",
      "[8600]\tdev-rmse:1.83579\n",
      "[8700]\tdev-rmse:1.83571\n",
      "[8800]\tdev-rmse:1.83578\n",
      "[8900]\tdev-rmse:1.83575\n",
      "[9000]\tdev-rmse:1.83584\n",
      "[9100]\tdev-rmse:1.83579\n",
      "[9104]\tdev-rmse:1.83578\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.14898\n",
      "[100]\tdev-rmse:2.08681\n",
      "[200]\tdev-rmse:1.93044\n",
      "[300]\tdev-rmse:1.89642\n",
      "[400]\tdev-rmse:1.88231\n",
      "[500]\tdev-rmse:1.87353\n",
      "[600]\tdev-rmse:1.86807\n",
      "[700]\tdev-rmse:1.86384\n",
      "[800]\tdev-rmse:1.86056\n",
      "[900]\tdev-rmse:1.85779\n",
      "[1000]\tdev-rmse:1.85536\n",
      "[1100]\tdev-rmse:1.85316\n",
      "[1200]\tdev-rmse:1.85106\n",
      "[1300]\tdev-rmse:1.84952\n",
      "[1400]\tdev-rmse:1.84772\n",
      "[1500]\tdev-rmse:1.84630\n",
      "[1600]\tdev-rmse:1.84534\n",
      "[1700]\tdev-rmse:1.84412\n",
      "[1800]\tdev-rmse:1.84308\n",
      "[1900]\tdev-rmse:1.84211\n",
      "[2000]\tdev-rmse:1.84129\n",
      "[2100]\tdev-rmse:1.84061\n",
      "[2200]\tdev-rmse:1.84015\n",
      "[2300]\tdev-rmse:1.83952\n",
      "[2400]\tdev-rmse:1.83903\n",
      "[2500]\tdev-rmse:1.83844\n",
      "[2600]\tdev-rmse:1.83776\n",
      "[2700]\tdev-rmse:1.83761\n",
      "[2800]\tdev-rmse:1.83736\n",
      "[2900]\tdev-rmse:1.83704\n",
      "[3000]\tdev-rmse:1.83665\n",
      "[3100]\tdev-rmse:1.83641\n",
      "[3200]\tdev-rmse:1.83600\n",
      "[3300]\tdev-rmse:1.83584\n",
      "[3400]\tdev-rmse:1.83564\n",
      "[3500]\tdev-rmse:1.83535\n",
      "[3600]\tdev-rmse:1.83518\n",
      "[3700]\tdev-rmse:1.83486\n",
      "[3800]\tdev-rmse:1.83476\n",
      "[3900]\tdev-rmse:1.83465\n",
      "[4000]\tdev-rmse:1.83453\n",
      "[4100]\tdev-rmse:1.83437\n",
      "[4200]\tdev-rmse:1.83418\n",
      "[4300]\tdev-rmse:1.83415\n",
      "[4400]\tdev-rmse:1.83413\n",
      "[4500]\tdev-rmse:1.83413\n",
      "[4600]\tdev-rmse:1.83404\n",
      "[4700]\tdev-rmse:1.83403\n",
      "[4800]\tdev-rmse:1.83389\n",
      "[4900]\tdev-rmse:1.83381\n",
      "[5000]\tdev-rmse:1.83375\n",
      "[5100]\tdev-rmse:1.83373\n",
      "[5200]\tdev-rmse:1.83363\n",
      "[5300]\tdev-rmse:1.83365\n",
      "[5400]\tdev-rmse:1.83366\n",
      "[5500]\tdev-rmse:1.83369\n",
      "[5600]\tdev-rmse:1.83362\n",
      "[5700]\tdev-rmse:1.83349\n",
      "[5800]\tdev-rmse:1.83336\n",
      "[5900]\tdev-rmse:1.83330\n",
      "[6000]\tdev-rmse:1.83323\n",
      "[6100]\tdev-rmse:1.83311\n",
      "[6200]\tdev-rmse:1.83312\n",
      "[6300]\tdev-rmse:1.83321\n",
      "[6400]\tdev-rmse:1.83322\n",
      "[6500]\tdev-rmse:1.83322\n",
      "[6514]\tdev-rmse:1.83322\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.18180\n",
      "[100]\tdev-rmse:2.11563\n",
      "[200]\tdev-rmse:1.95697\n",
      "[300]\tdev-rmse:1.92122\n",
      "[400]\tdev-rmse:1.90619\n",
      "[500]\tdev-rmse:1.89650\n",
      "[600]\tdev-rmse:1.88990\n",
      "[700]\tdev-rmse:1.88481\n",
      "[800]\tdev-rmse:1.88163\n",
      "[900]\tdev-rmse:1.87808\n",
      "[1000]\tdev-rmse:1.87514\n",
      "[1100]\tdev-rmse:1.87304\n",
      "[1200]\tdev-rmse:1.87081\n",
      "[1300]\tdev-rmse:1.86876\n",
      "[1400]\tdev-rmse:1.86698\n",
      "[1500]\tdev-rmse:1.86552\n",
      "[1600]\tdev-rmse:1.86412\n",
      "[1700]\tdev-rmse:1.86268\n",
      "[1800]\tdev-rmse:1.86158\n",
      "[1900]\tdev-rmse:1.86045\n",
      "[2000]\tdev-rmse:1.85953\n",
      "[2100]\tdev-rmse:1.85877\n",
      "[2200]\tdev-rmse:1.85835\n",
      "[2300]\tdev-rmse:1.85772\n",
      "[2400]\tdev-rmse:1.85692\n",
      "[2500]\tdev-rmse:1.85649\n",
      "[2600]\tdev-rmse:1.85602\n",
      "[2700]\tdev-rmse:1.85566\n",
      "[2800]\tdev-rmse:1.85522\n",
      "[2900]\tdev-rmse:1.85477\n",
      "[3000]\tdev-rmse:1.85441\n",
      "[3100]\tdev-rmse:1.85411\n",
      "[3200]\tdev-rmse:1.85382\n",
      "[3300]\tdev-rmse:1.85347\n",
      "[3400]\tdev-rmse:1.85290\n",
      "[3500]\tdev-rmse:1.85261\n",
      "[3600]\tdev-rmse:1.85231\n",
      "[3700]\tdev-rmse:1.85201\n",
      "[3800]\tdev-rmse:1.85188\n",
      "[3900]\tdev-rmse:1.85173\n",
      "[4000]\tdev-rmse:1.85150\n",
      "[4100]\tdev-rmse:1.85132\n",
      "[4200]\tdev-rmse:1.85120\n",
      "[4300]\tdev-rmse:1.85111\n",
      "[4400]\tdev-rmse:1.85095\n",
      "[4500]\tdev-rmse:1.85082\n",
      "[4600]\tdev-rmse:1.85086\n",
      "[4700]\tdev-rmse:1.85071\n",
      "[4800]\tdev-rmse:1.85045\n",
      "[4900]\tdev-rmse:1.85038\n",
      "[5000]\tdev-rmse:1.85027\n",
      "[5100]\tdev-rmse:1.85012\n",
      "[5200]\tdev-rmse:1.84993\n",
      "[5300]\tdev-rmse:1.84985\n",
      "[5400]\tdev-rmse:1.84991\n",
      "[5500]\tdev-rmse:1.84980\n",
      "[5600]\tdev-rmse:1.84967\n",
      "[5700]\tdev-rmse:1.84968\n",
      "[5800]\tdev-rmse:1.84948\n",
      "[5900]\tdev-rmse:1.84954\n",
      "[6000]\tdev-rmse:1.84935\n",
      "[6100]\tdev-rmse:1.84922\n",
      "[6200]\tdev-rmse:1.84915\n",
      "[6300]\tdev-rmse:1.84927\n",
      "[6400]\tdev-rmse:1.84912\n",
      "[6500]\tdev-rmse:1.84901\n",
      "[6600]\tdev-rmse:1.84903\n",
      "[6700]\tdev-rmse:1.84894\n",
      "[6800]\tdev-rmse:1.84901\n",
      "[6900]\tdev-rmse:1.84908\n",
      "[7000]\tdev-rmse:1.84914\n",
      "[7098]\tdev-rmse:1.84914\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.15374\n",
      "[100]\tdev-rmse:2.10048\n",
      "[200]\tdev-rmse:1.94649\n",
      "[300]\tdev-rmse:1.91073\n",
      "[400]\tdev-rmse:1.89741\n",
      "[500]\tdev-rmse:1.88915\n",
      "[600]\tdev-rmse:1.88345\n",
      "[700]\tdev-rmse:1.87877\n",
      "[800]\tdev-rmse:1.87550\n",
      "[900]\tdev-rmse:1.87221\n",
      "[1000]\tdev-rmse:1.86969\n",
      "[1100]\tdev-rmse:1.86768\n",
      "[1200]\tdev-rmse:1.86574\n",
      "[1300]\tdev-rmse:1.86394\n",
      "[1400]\tdev-rmse:1.86254\n",
      "[1500]\tdev-rmse:1.86104\n",
      "[1600]\tdev-rmse:1.85983\n",
      "[1700]\tdev-rmse:1.85872\n",
      "[1800]\tdev-rmse:1.85769\n",
      "[1900]\tdev-rmse:1.85661\n",
      "[2000]\tdev-rmse:1.85568\n",
      "[2100]\tdev-rmse:1.85507\n",
      "[2200]\tdev-rmse:1.85462\n",
      "[2300]\tdev-rmse:1.85411\n",
      "[2400]\tdev-rmse:1.85348\n",
      "[2500]\tdev-rmse:1.85292\n",
      "[2600]\tdev-rmse:1.85233\n",
      "[2700]\tdev-rmse:1.85169\n",
      "[2800]\tdev-rmse:1.85133\n",
      "[2900]\tdev-rmse:1.85092\n",
      "[3000]\tdev-rmse:1.85054\n",
      "[3100]\tdev-rmse:1.85003\n",
      "[3200]\tdev-rmse:1.84970\n",
      "[3300]\tdev-rmse:1.84938\n",
      "[3400]\tdev-rmse:1.84911\n",
      "[3500]\tdev-rmse:1.84888\n",
      "[3600]\tdev-rmse:1.84876\n",
      "[3700]\tdev-rmse:1.84848\n",
      "[3800]\tdev-rmse:1.84815\n",
      "[3900]\tdev-rmse:1.84813\n",
      "[4000]\tdev-rmse:1.84799\n",
      "[4100]\tdev-rmse:1.84772\n",
      "[4200]\tdev-rmse:1.84758\n",
      "[4300]\tdev-rmse:1.84739\n",
      "[4400]\tdev-rmse:1.84730\n",
      "[4500]\tdev-rmse:1.84715\n",
      "[4600]\tdev-rmse:1.84693\n",
      "[4700]\tdev-rmse:1.84693\n",
      "[4800]\tdev-rmse:1.84690\n",
      "[4900]\tdev-rmse:1.84674\n",
      "[5000]\tdev-rmse:1.84663\n",
      "[5100]\tdev-rmse:1.84650\n",
      "[5200]\tdev-rmse:1.84639\n",
      "[5300]\tdev-rmse:1.84623\n",
      "[5400]\tdev-rmse:1.84610\n",
      "[5500]\tdev-rmse:1.84605\n",
      "[5600]\tdev-rmse:1.84601\n",
      "[5700]\tdev-rmse:1.84614\n",
      "[5800]\tdev-rmse:1.84614\n",
      "[5900]\tdev-rmse:1.84599\n",
      "[6000]\tdev-rmse:1.84598\n",
      "[6100]\tdev-rmse:1.84586\n",
      "[6200]\tdev-rmse:1.84579\n",
      "[6300]\tdev-rmse:1.84568\n",
      "[6400]\tdev-rmse:1.84568\n",
      "[6500]\tdev-rmse:1.84569\n",
      "[6600]\tdev-rmse:1.84573\n",
      "[6700]\tdev-rmse:1.84580\n",
      "[6725]\tdev-rmse:1.84588\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:3.12850\n",
      "[100]\tdev-rmse:2.06287\n",
      "[200]\tdev-rmse:1.90630\n",
      "[300]\tdev-rmse:1.87213\n",
      "[400]\tdev-rmse:1.85815\n",
      "[500]\tdev-rmse:1.85005\n",
      "[600]\tdev-rmse:1.84447\n",
      "[700]\tdev-rmse:1.83970\n",
      "[800]\tdev-rmse:1.83646\n",
      "[900]\tdev-rmse:1.83398\n",
      "[1000]\tdev-rmse:1.83145\n",
      "[1100]\tdev-rmse:1.82964\n",
      "[1200]\tdev-rmse:1.82801\n",
      "[1300]\tdev-rmse:1.82638\n",
      "[1400]\tdev-rmse:1.82499\n",
      "[1500]\tdev-rmse:1.82398\n",
      "[1600]\tdev-rmse:1.82299\n",
      "[1700]\tdev-rmse:1.82187\n",
      "[1800]\tdev-rmse:1.82121\n",
      "[1900]\tdev-rmse:1.82044\n",
      "[2000]\tdev-rmse:1.81979\n",
      "[2100]\tdev-rmse:1.81908\n",
      "[2200]\tdev-rmse:1.81844\n",
      "[2300]\tdev-rmse:1.81798\n",
      "[2400]\tdev-rmse:1.81749\n",
      "[2500]\tdev-rmse:1.81722\n",
      "[2600]\tdev-rmse:1.81685\n",
      "[2700]\tdev-rmse:1.81662\n",
      "[2800]\tdev-rmse:1.81641\n",
      "[2900]\tdev-rmse:1.81602\n",
      "[3000]\tdev-rmse:1.81582\n",
      "[3100]\tdev-rmse:1.81547\n",
      "[3200]\tdev-rmse:1.81519\n",
      "[3300]\tdev-rmse:1.81489\n",
      "[3400]\tdev-rmse:1.81476\n",
      "[3500]\tdev-rmse:1.81454\n",
      "[3600]\tdev-rmse:1.81431\n",
      "[3700]\tdev-rmse:1.81418\n",
      "[3800]\tdev-rmse:1.81407\n",
      "[3900]\tdev-rmse:1.81389\n",
      "[4000]\tdev-rmse:1.81381\n",
      "[4100]\tdev-rmse:1.81373\n",
      "[4200]\tdev-rmse:1.81358\n",
      "[4300]\tdev-rmse:1.81348\n",
      "[4400]\tdev-rmse:1.81345\n",
      "[4500]\tdev-rmse:1.81339\n",
      "[4600]\tdev-rmse:1.81320\n",
      "[4700]\tdev-rmse:1.81315\n",
      "[4800]\tdev-rmse:1.81324\n",
      "[4900]\tdev-rmse:1.81324\n",
      "[5000]\tdev-rmse:1.81324\n",
      "[5100]\tdev-rmse:1.81324\n",
      "[5154]\tdev-rmse:1.81341\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(train_df.shape[0])\n",
    "pred = np.zeros(test_df.shape[0])\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index)):\n",
    "    print(f'fold={i}', '- ' * 20)\n",
    "    trn_data = xgb.DMatrix(train_df.loc[trn_idx, train_cols], label=train_df.loc[trn_idx, target_col])\n",
    "    val_data = xgb.DMatrix(train_df.loc[val_idx, train_cols], label=train_df.loc[val_idx, target_col])\n",
    "    tst_data = xgb.DMatrix(test_df[train_cols])\n",
    "\n",
    "    model = xgb.train(params, trn_data, 10000, evals=[(val_data, 'dev')], early_stopping_rounds=400, verbose_eval=100)\n",
    "\n",
    "    oof[val_idx] = model.predict(val_data, iteration_range=(0, model.best_iteration + 1))\n",
    "    pred += model.predict(tst_data, iteration_range=(0, model.best_iteration + 1)) / nfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53d90276-7ad2-4b92-84e4-6c47196428f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.expm1(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c073e517-46a0-4016-8564-7d83d31267f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.746888355643476"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_log_error(train_df['Rings'], oof, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d41027-db76-433d-b0c4-53e3a3af38f6",
   "metadata": {},
   "source": [
    "#### StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c1a8d8b-7b51-496b-913e-b890e5e7ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nthread': 8,\n",
    "    'objective': 'reg:squarederror',    # reg:squaredlogerror\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.015,\n",
    "    'min_child_weight': 22.4,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_lambda': 8.0,\n",
    "    'eval_metric': 'rmse',    # rmsle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28485416-9b08-4a88-9fc0-73893b90ecdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold=0 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28306\n",
      "[200]\tdev-rmse:0.15727\n",
      "[400]\tdev-rmse:0.15316\n",
      "[600]\tdev-rmse:0.15203\n",
      "[800]\tdev-rmse:0.15147\n",
      "[1000]\tdev-rmse:0.15110\n",
      "[1200]\tdev-rmse:0.15080\n",
      "[1400]\tdev-rmse:0.15057\n",
      "[1600]\tdev-rmse:0.15038\n",
      "[1800]\tdev-rmse:0.15023\n",
      "[2000]\tdev-rmse:0.15011\n",
      "[2200]\tdev-rmse:0.15002\n",
      "[2400]\tdev-rmse:0.14993\n",
      "[2600]\tdev-rmse:0.14986\n",
      "[2800]\tdev-rmse:0.14981\n",
      "[3000]\tdev-rmse:0.14975\n",
      "[3200]\tdev-rmse:0.14969\n",
      "[3400]\tdev-rmse:0.14965\n",
      "[3600]\tdev-rmse:0.14961\n",
      "[3800]\tdev-rmse:0.14958\n",
      "[4000]\tdev-rmse:0.14954\n",
      "[4200]\tdev-rmse:0.14952\n",
      "[4400]\tdev-rmse:0.14950\n",
      "[4600]\tdev-rmse:0.14946\n",
      "[4800]\tdev-rmse:0.14944\n",
      "[5000]\tdev-rmse:0.14941\n",
      "[5200]\tdev-rmse:0.14941\n",
      "[5400]\tdev-rmse:0.14940\n",
      "[5600]\tdev-rmse:0.14940\n",
      "[5800]\tdev-rmse:0.14939\n",
      "[6000]\tdev-rmse:0.14938\n",
      "[6200]\tdev-rmse:0.14937\n",
      "[6400]\tdev-rmse:0.14936\n",
      "[6600]\tdev-rmse:0.14936\n",
      "[6800]\tdev-rmse:0.14936\n",
      "[7000]\tdev-rmse:0.14936\n",
      "[7200]\tdev-rmse:0.14936\n",
      "[7297]\tdev-rmse:0.14936\n",
      "fold=1 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28311\n",
      "[200]\tdev-rmse:0.15597\n",
      "[400]\tdev-rmse:0.15201\n",
      "[600]\tdev-rmse:0.15074\n",
      "[800]\tdev-rmse:0.15013\n",
      "[1000]\tdev-rmse:0.14973\n",
      "[1200]\tdev-rmse:0.14941\n",
      "[1400]\tdev-rmse:0.14913\n",
      "[1600]\tdev-rmse:0.14896\n",
      "[1800]\tdev-rmse:0.14882\n",
      "[2000]\tdev-rmse:0.14868\n",
      "[2200]\tdev-rmse:0.14861\n",
      "[2400]\tdev-rmse:0.14851\n",
      "[2600]\tdev-rmse:0.14843\n",
      "[2800]\tdev-rmse:0.14838\n",
      "[3000]\tdev-rmse:0.14833\n",
      "[3200]\tdev-rmse:0.14828\n",
      "[3400]\tdev-rmse:0.14824\n",
      "[3600]\tdev-rmse:0.14821\n",
      "[3800]\tdev-rmse:0.14817\n",
      "[4000]\tdev-rmse:0.14814\n",
      "[4200]\tdev-rmse:0.14813\n",
      "[4400]\tdev-rmse:0.14812\n",
      "[4600]\tdev-rmse:0.14809\n",
      "[4800]\tdev-rmse:0.14807\n",
      "[5000]\tdev-rmse:0.14806\n",
      "[5200]\tdev-rmse:0.14804\n",
      "[5400]\tdev-rmse:0.14804\n",
      "[5600]\tdev-rmse:0.14803\n",
      "[5800]\tdev-rmse:0.14802\n",
      "[6000]\tdev-rmse:0.14802\n",
      "[6200]\tdev-rmse:0.14801\n",
      "[6400]\tdev-rmse:0.14801\n",
      "[6600]\tdev-rmse:0.14801\n",
      "[6800]\tdev-rmse:0.14802\n",
      "[6846]\tdev-rmse:0.14801\n",
      "fold=2 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28308\n",
      "[200]\tdev-rmse:0.15760\n",
      "[400]\tdev-rmse:0.15339\n",
      "[600]\tdev-rmse:0.15209\n",
      "[800]\tdev-rmse:0.15151\n",
      "[1000]\tdev-rmse:0.15110\n",
      "[1200]\tdev-rmse:0.15079\n",
      "[1400]\tdev-rmse:0.15055\n",
      "[1600]\tdev-rmse:0.15034\n",
      "[1800]\tdev-rmse:0.15016\n",
      "[2000]\tdev-rmse:0.15001\n",
      "[2200]\tdev-rmse:0.14992\n",
      "[2400]\tdev-rmse:0.14982\n",
      "[2600]\tdev-rmse:0.14973\n",
      "[2800]\tdev-rmse:0.14966\n",
      "[3000]\tdev-rmse:0.14960\n",
      "[3200]\tdev-rmse:0.14954\n",
      "[3400]\tdev-rmse:0.14949\n",
      "[3600]\tdev-rmse:0.14944\n",
      "[3800]\tdev-rmse:0.14940\n",
      "[4000]\tdev-rmse:0.14937\n",
      "[4200]\tdev-rmse:0.14935\n",
      "[4400]\tdev-rmse:0.14931\n",
      "[4600]\tdev-rmse:0.14927\n",
      "[4800]\tdev-rmse:0.14926\n",
      "[5000]\tdev-rmse:0.14924\n",
      "[5200]\tdev-rmse:0.14923\n",
      "[5400]\tdev-rmse:0.14921\n",
      "[5600]\tdev-rmse:0.14920\n",
      "[5800]\tdev-rmse:0.14920\n",
      "[6000]\tdev-rmse:0.14918\n",
      "[6200]\tdev-rmse:0.14918\n",
      "[6400]\tdev-rmse:0.14917\n",
      "[6600]\tdev-rmse:0.14917\n",
      "[6800]\tdev-rmse:0.14917\n",
      "[7000]\tdev-rmse:0.14918\n",
      "[7105]\tdev-rmse:0.14917\n",
      "fold=3 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28326\n",
      "[200]\tdev-rmse:0.15865\n",
      "[400]\tdev-rmse:0.15443\n",
      "[600]\tdev-rmse:0.15328\n",
      "[800]\tdev-rmse:0.15264\n",
      "[1000]\tdev-rmse:0.15223\n",
      "[1200]\tdev-rmse:0.15190\n",
      "[1400]\tdev-rmse:0.15162\n",
      "[1600]\tdev-rmse:0.15142\n",
      "[1800]\tdev-rmse:0.15126\n",
      "[2000]\tdev-rmse:0.15113\n",
      "[2200]\tdev-rmse:0.15102\n",
      "[2400]\tdev-rmse:0.15090\n",
      "[2600]\tdev-rmse:0.15084\n",
      "[2800]\tdev-rmse:0.15076\n",
      "[3000]\tdev-rmse:0.15069\n",
      "[3200]\tdev-rmse:0.15063\n",
      "[3400]\tdev-rmse:0.15057\n",
      "[3600]\tdev-rmse:0.15053\n",
      "[3800]\tdev-rmse:0.15049\n",
      "[4000]\tdev-rmse:0.15046\n",
      "[4200]\tdev-rmse:0.15043\n",
      "[4400]\tdev-rmse:0.15040\n",
      "[4600]\tdev-rmse:0.15037\n",
      "[4800]\tdev-rmse:0.15035\n",
      "[5000]\tdev-rmse:0.15033\n",
      "[5200]\tdev-rmse:0.15031\n",
      "[5400]\tdev-rmse:0.15029\n",
      "[5600]\tdev-rmse:0.15029\n",
      "[5800]\tdev-rmse:0.15028\n",
      "[6000]\tdev-rmse:0.15027\n",
      "[6200]\tdev-rmse:0.15026\n",
      "[6400]\tdev-rmse:0.15025\n",
      "[6600]\tdev-rmse:0.15024\n",
      "[6800]\tdev-rmse:0.15023\n",
      "[7000]\tdev-rmse:0.15022\n",
      "[7200]\tdev-rmse:0.15022\n",
      "[7400]\tdev-rmse:0.15022\n",
      "[7600]\tdev-rmse:0.15022\n",
      "[7694]\tdev-rmse:0.15022\n",
      "fold=4 - - - - - - - - - - - - - - - - - - - - \n",
      "[0]\tdev-rmse:0.28306\n",
      "[200]\tdev-rmse:0.15738\n",
      "[400]\tdev-rmse:0.15335\n",
      "[600]\tdev-rmse:0.15206\n",
      "[800]\tdev-rmse:0.15148\n",
      "[1000]\tdev-rmse:0.15104\n",
      "[1200]\tdev-rmse:0.15072\n",
      "[1400]\tdev-rmse:0.15045\n",
      "[1600]\tdev-rmse:0.15024\n"
     ]
    }
   ],
   "source": [
    "cv, oof, pred = xgb_cv(params, train_df, test_df, train_cols, target_col, log_transform=True, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4019f6e-1fbf-495d-a6ff-132ceda98ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'xgb_bo_log1p_skf'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d538cae-8dfe-4554-a5c0-5547c8ddc995",
   "metadata": {},
   "source": [
    "### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ea440-f2eb-425a-a481-205bbe538f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False, nfold=5, num_boost_round=10000):\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        folds = KFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "\n",
    "    target = train_df[target_col]\n",
    "    if log_transform:\n",
    "        target = np.log1p(train_df[target_col])\n",
    "    \n",
    "    oof = np.zeros(train_df.shape[0])\n",
    "    pred = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    for i, (trn_idx, val_idx) in enumerate(folds.split(train_df.index, train_df.Rings.astype(int))):\n",
    "        print(f'fold={i}', '- ' * 20)\n",
    "        trn_data = cb.Pool(train_df.loc[trn_idx, train_cols], label=target.loc[trn_idx], feature_names=train_cols, cat_features=['Sex_code'])\n",
    "        val_data = cb.Pool(train_df.loc[val_idx, train_cols], label=target.loc[val_idx], feature_names=train_cols, cat_features=['Sex_code'])\n",
    "    \n",
    "        tst_data = cb.Pool(test_df[train_cols], feature_names=train_cols, cat_features=['Sex_code'])\n",
    "    \n",
    "        model = cb.train(trn_data, params, iterations=10000, evals=val_data, early_stopping_rounds=400, verbose_eval=200)\n",
    "    \n",
    "        oof[val_idx] = model.predict(val_data, ntree_end=model.best_iteration_)\n",
    "        pred += model.predict(tst_data, ntree_end=model.best_iteration_) / nfold\n",
    "\n",
    "    if log_transform:\n",
    "        oof = np.expm1(oof)\n",
    "        pred = np.expm1(pred)\n",
    "\n",
    "    cv = mean_squared_log_error(train_df['Rings'], oof, squared=False)\n",
    "    return cv, oof, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fbdbb-4a62-4765-873a-5e2e2a6e042b",
   "metadata": {},
   "source": [
    "#### 默参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee162d3c-d49a-40e6-bde5-b0915cf17d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'thread_count': 8,\n",
    "    'objective': 'RMSE',    # reg:squaredlogerror\n",
    "    'max_depth': 6,\n",
    "    # 'learning_rate': 0.03,\n",
    "    'min_data_in_leaf': 1,\n",
    "    # 'subsample': 1.0,\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'reg_lambda': 3,\n",
    "    'eval_metric': 'RMSE',    # rmsle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdac68-0d65-4f62-a16a-8e119e3158cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv, oof, pred = cb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431b391-13e1-43e7-9a16-304949ed82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'cb_default'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c696b3f-54cb-44bb-b8fd-51788b5374fd",
   "metadata": {},
   "source": [
    "#### 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409b377-e452-408e-bf57-739130d53ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'target': -0.14920691782699697, 'params': {'colsample_bylevel': 0.444138725358572, 'learning_rate': 0.021914249401391334, 'max_depth': 5.989341011049182, 'min_data_in_leaf': 3.8619321720075757, 'reg_lambda': 5.839227436758772, 'subsample': 0.8828478540185538}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bc690-83da-4c51-85ff-4ec99b2daef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'thread_count': 8,\n",
    "    'objective': 'RMSE',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.02,\n",
    "    'min_data_in_leaf': 4,\n",
    "    'subsample': 0.88,\n",
    "    'colsample_bylevel': 0.44,\n",
    "    'reg_lambda': 5.8,\n",
    "    'eval_metric': 'RMSE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2560844-8533-4fe2-9554-d1c34d378e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv, oof, pred = cb_cv(params, train_df, test_df, train_cols, target_col, log_transform=False, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34d9ef-ce47-4d94-b5eb-53285548791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'cb_bo'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02327416-b20f-4543-b1a8-a0fd8d2d30fa",
   "metadata": {},
   "source": [
    "#### Rings_log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f964d-e258-4c04-90f6-701726142d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'thread_count': 8,\n",
    "    'objective': 'RMSE',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.02,\n",
    "    'min_data_in_leaf': 4,\n",
    "    'subsample': 0.88,\n",
    "    'colsample_bylevel': 0.44,\n",
    "    'reg_lambda': 5.8,\n",
    "    'eval_metric': 'RMSE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba154b-1bfc-4566-a726-d29fcd645d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv, oof, pred = cb_cv(params, train_df, test_df, train_cols, target_col, log_transform=True, stratified=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7eff4b-b750-4ddf-92eb-39dcf5ca9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'cb_bo_log1p'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd6e08-c2d0-40bb-bdd6-bad68e64d547",
   "metadata": {},
   "source": [
    "#### StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020eb9b-5fa7-477c-a00f-0c20b145fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'thread_count': 8,\n",
    "    'objective': 'RMSE',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.02,\n",
    "    'min_data_in_leaf': 4,\n",
    "    'subsample': 0.88,\n",
    "    'colsample_bylevel': 0.44,\n",
    "    'reg_lambda': 5.8,\n",
    "    'eval_metric': 'RMSE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bd108-206f-4ad7-bbe3-2a9423c1c1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv, oof, pred = cb_cv(params, train_df, test_df, train_cols, target_col, log_transform=True, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2effc-1d44-4ab7-a0e6-271111393851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv)\n",
    "\n",
    "tag = 'cb_bo_log1p_skf'\n",
    "oof_df[tag] = oof\n",
    "pred_df[tag] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2511d-081d-4baf-8679-dd11c1907362",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3c28c-63a3-4ea4-b126-338dd6551e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b352f-8cf3-46cc-80c3-2afcb61026dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ce671-20af-4458-ac44-2412344ef42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f05c20-c2c8-40fd-9d3b-a6f7110d9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73afbc-5ee0-427c-82c5-8bbdd9cd616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tags = []\n",
    "for m in ['lgb', 'xgb', 'cb']:\n",
    "    model_tags += [f'{m}_default', f'{m}_bo', f'{m}_bo_log1p', f'{m}_bo_log1p_skf']\n",
    "model_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9802b-ba85-4ce0-8425-59cbbbf9e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = []\n",
    "for col in model_tags:\n",
    "    metric_df.append([col, mean_squared_log_error(oof_df['Rings'], oof_df[col], squared=False)])\n",
    "metric_df = pd.DataFrame(metric_df, columns=['model_tag', 'rmsle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62f898a4-22d4-4e75-8daf-d754f794bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_tag</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgb_default</td>\n",
       "      <td>0.149999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgb_bo</td>\n",
       "      <td>0.149424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgb_bo_log1p</td>\n",
       "      <td>0.148720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb_bo_log1p_skf</td>\n",
       "      <td>0.148637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgb_default</td>\n",
       "      <td>0.151314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb_bo</td>\n",
       "      <td>0.149852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgb_bo_log1p</td>\n",
       "      <td>0.149197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgb_bo_log1p_skf</td>\n",
       "      <td>0.149143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cb_default</td>\n",
       "      <td>0.149755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cb_bo</td>\n",
       "      <td>0.149618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cb_bo_log1p</td>\n",
       "      <td>0.148950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cb_bo_log1p_skf</td>\n",
       "      <td>0.148853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_tag     rmsle\n",
       "0        lgb_default  0.149999\n",
       "1             lgb_bo  0.149424\n",
       "2       lgb_bo_log1p  0.148720\n",
       "3   lgb_bo_log1p_skf  0.148637\n",
       "4        xgb_default  0.151314\n",
       "5             xgb_bo  0.149852\n",
       "6       xgb_bo_log1p  0.149197\n",
       "7   xgb_bo_log1p_skf  0.149143\n",
       "8         cb_default  0.149755\n",
       "9              cb_bo  0.149618\n",
       "10       cb_bo_log1p  0.148950\n",
       "11   cb_bo_log1p_skf  0.148853"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e7a0305-7127-4954-a998-ef4e77f3a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, c in zip(range(0, 12, 4), ['r', 'g', 'b']):\n",
    "    df = metric_df.loc[i:(i+4)]\n",
    "    plt.plot(df.index, df.rmsle, '*', c=c)\n",
    "\n",
    "plt.xticks(ticks=metric_df.index, labels=metric_df.model_tag, rotation=90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "258f0cd2-8293-4bdd-8974-f3d9df6fa43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bcf509f2-7138-4a5d-b1d5-85a25bd883b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.fit(oof_df[model_tags], oof_df['Rings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ad3ab674-65b9-41a1-8353-51d7a807be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ensemble_pred = ensemble_model.predict(pred_df[model_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b7d58486-6247-4f35-adbf-ff070c001c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.69071961,  9.55985433, 10.20571465, ..., 11.95026242,\n",
       "       14.0869782 ,  8.32682338])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363c22c-ff6d-425e-97b3-742000df8e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07510a2d-18a0-435d-9949-a9c98321f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_cv(oof_df, pred_df, train_cols):\n",
    "    nfold = 5\n",
    "    folds = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42)\n",
    "    \n",
    "    oof = np.zeros(oof_df.shape[0])\n",
    "    pred = np.zeros(pred_df.shape[0])\n",
    "    \n",
    "    for i, (trn_idx, val_idx) in enumerate(folds.split(oof_df.index, oof_df.Rings.astype(int))):\n",
    "        print(f'fold={i}', '- ' * 20)\n",
    "        trn_X = oof_df.loc[trn_idx, train_cols]\n",
    "        trn_y = oof_df.loc[trn_idx, 'Rings']\n",
    "\n",
    "        val_X = oof_df.loc[val_idx, train_cols]\n",
    "        val_y = oof_df.loc[val_idx, 'Rings']\n",
    "        \n",
    "        tst_X = pred_df[train_cols]\n",
    "\n",
    "        model = Ridge()\n",
    "        model.fit(trn_X, trn_y)\n",
    "\n",
    "        oof[val_idx] = model.predict(val_X)\n",
    "        pred += model.predict(tst_X) / nfold\n",
    "\n",
    "    cv = mean_squared_log_error(oof_df['Rings'], oof, squared=False)\n",
    "    return cv, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c34f32-8fe4-46b0-8d6a-460fe5f76f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_cv, ensemble_pred = ensemble_cv(oof_df, pred_df, model_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "704e0a02-3170-4593-8254-3c4aed837a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14873459558729193"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1024b45-c794-44bd-b83e-7859df24fe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.79611278,  9.78543487, 10.00996596, ..., 12.61777516,\n",
       "       13.94584236,  8.32657144])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce903e-ec8c-4551-9bd9-9dad991c3c23",
   "metadata": {},
   "source": [
    "## Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f255a58-7ced-4097-b49d-ad1644678d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df0c42-71de-48dd-b6bf-3ddb70578406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fdb50b3-0e2c-41ab-a923-e5084277e6a5",
   "metadata": {},
   "source": [
    "## 提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "690ee020-0e9f-49ae-b515-110871860798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7764975-c23f-4293-aadb-169797d87718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90615</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90616</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90617</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90618</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90619</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Rings\n",
       "0  90615     10\n",
       "1  90616     10\n",
       "2  90617     10\n",
       "3  90618     10\n",
       "4  90619     10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "796113f9-7756-4ecf-8627-25edf4dfd367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub_df['id'] == test_df['id']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b24b077c-8b91-47fb-b4a3-5ba511423b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单模型最优\n",
    "pred_df['Rings'] = pred_df['lgb_bo_log1p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "56353a1e-06eb-40f7-84f4-284e1a69afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble cv pred\n",
    "pred_df['Rings'] = ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4fafb58e-b6ea-4a64-affd-4f4f9c119367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble simple pred\n",
    "pred_df['Rings'] = simple_ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1f046503-99b2-406b-8929-c94bf7988268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more data pred cv=0.1487\n",
    "pred_df['Rings'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "828e4a57-cbfa-4583-9724-a5485f0a4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'Rings']\n",
    "pred_df[cols].to_csv('more_data_pred.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7c5e8063-cd61-452a-b157-a218d09f51dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Rings\n",
      "90615,9.837206952449687\n",
      "90616,9.777940900929194\n",
      "90617,9.825952536578335\n",
      "90618,10.639116793945018\n",
      "90619,7.613494892754508\n",
      "90620,9.365750582343113\n",
      "90621,10.682615043884145\n",
      "90622,6.050469067537613\n",
      "90623,7.92449544670273\n"
     ]
    }
   ],
   "source": [
    "!head more_data_pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe0bc874-a927-4d1f-807d-071752f1bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,Rings\n",
      "90615,10\n",
      "90616,10\n",
      "90617,10\n",
      "90618,10\n",
      "90619,10\n",
      "90620,10\n",
      "90621,10\n",
      "90622,10\n",
      "90623,10\n"
     ]
    }
   ],
   "source": [
    "!head ../input/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04444cb-49dd-425d-9b2d-6fa1e70f2b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
